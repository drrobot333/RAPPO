{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mmap\n",
    "import time\n",
    "from time import strftime, localtime\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "import import_ipynb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import collections\n",
    "import sys \n",
    "import win32pipe, win32file, pywintypes\n",
    "\n",
    "from actor import actor_network\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendOmnetMessage(msg):\n",
    "    win32file.WriteFile(pipe, msg.encode('utf-8'))\n",
    "    \n",
    "def getOmnetMessage():\n",
    "    response_byte = win32file.ReadFile(pipe, BUFFER_SIZE)\n",
    "    response_str = response_byte[1].decode('utf-8')\n",
    "    return response_str\n",
    "\n",
    "def closePipe():\n",
    "    win32file.CloseHandle(pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험 정보 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordExpInfo(config):\n",
    "\n",
    "    networkInfo = config[\"network_info\"]\n",
    "\n",
    "    modelNum = int(networkInfo['modelNum'])\n",
    "    availableJobNum = int(networkInfo['availableJobNum'])\n",
    "    nodeNum = int(networkInfo['nodeNum'])\n",
    "    jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "    adjacency = eval(networkInfo['adjacencyList'])\n",
    "    episode_length = int(networkInfo['episode_length'])\n",
    "    node_capacity = networkInfo['node_capacity']\n",
    "    job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "    node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "    queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "    hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "    reward_weight = 1/modelNum\n",
    "    entropy_weight = config[\"entropy_weight\"]\n",
    "    \n",
    "    info = f\"\"\"\n",
    "    노드 개수 : {nodeNum}\n",
    "    네트워크 최대 job 개수 : {availableJobNum}\n",
    "    job 대기 가능 개수 : {jobWaitingLength}\n",
    "    최대 subtask 개수 : {modelNum}\n",
    "    인접 리스트 : {adjacency}\n",
    "    node_feature_num : {node_feature_num}\n",
    "    queue_feature_num : {queue_feature_num}\n",
    "    episode_length : {episode_length}\n",
    "    node_capacity : {node_capacity}\n",
    "    entropy_weight : {entropy_weight}\n",
    "    reward_weight : {reward_weight}\n",
    "    job_generate_rate : {job_generate_rate}\n",
    "    \"\"\"\n",
    "    print(info)\n",
    "\n",
    "    with open(f'{config[\"path_name\"]}/info.txt', 'w') as f:\n",
    "        f.write(f'{info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    global adjacency, writer\n",
    "\n",
    "    recordExpInfo(config)\n",
    "    \n",
    "    model = actor_network(config)\n",
    "    reward_history = []\n",
    "    v_history = []\n",
    "\n",
    "    adjacency = torch.tensor(adjacency, dtype=torch.long)\n",
    "\n",
    "    step = 1\n",
    "    episode = 1\n",
    "\n",
    "    max_reward = 0\n",
    "\n",
    "    average_reward = 0\n",
    "    average_reward_num = 0\n",
    "\n",
    "    temp_history = []\n",
    "\n",
    "    isStop = False\n",
    "    node_selected_num = [0 for i in range(config[\"node_num\"])]\n",
    "    void_selected_num = 0\n",
    "\n",
    "    pre_state_1 = {}\n",
    "    pre_state_2 = {}\n",
    "\n",
    "    model = model.cuda()\n",
    "    \n",
    "    while True:\n",
    "        # time.sleep(config[\"cpu_load_balance_time\"])\n",
    "        \n",
    "        msg = getOmnetMessage()\n",
    "        \n",
    "        if msg == \"action\": # omnet의 메세지, state 받으면 됨\n",
    "            sendOmnetMessage(\"ok\")\n",
    "            state_1 = getOmnetMessage()\n",
    "            state_2 = getOmnetMessage()\n",
    "\n",
    "            if len(state_1) == 0:\n",
    "                state_1 = state_2\n",
    "            \n",
    "\n",
    "            if len(pre_state_1) == 0: # action 시작\n",
    "                state_1 = json.loads(state_1) # state 받았으므로 action 하면됨.\n",
    "                state_2 = json.loads(state_2) # state 받았으므로 action 하면됨.\n",
    "                \n",
    "            else:\n",
    "                state_1 = json.loads(state_1)\n",
    "                pre_state_1['jobWaiting'] = state_1['jobWaiting']\n",
    "                pre_state_1['sojournTime'] = state_1['sojournTime']\n",
    "                state_1 = pre_state_1\n",
    "\n",
    "                state_2 = json.loads(state_2)\n",
    "                pre_state_2['jobWaiting'] = state_2['jobWaiting']\n",
    "                pre_state_2['sojournTime'] = state_2['sojournTime']\n",
    "                state_2 = pre_state_2\n",
    "            \n",
    "            sendOmnetMessage(\"ok\") # 답장\n",
    "\n",
    "            node_waiting_state_1 = np.array(eval(str(state_1['nodeState'])))\n",
    "            node_processing_state_1 = np.array(eval(state_1['nodeProcessing']))\n",
    "            link_state_1 = np.array(eval(state_1['linkWaiting']))\n",
    "            job_waiting_state_1 = np.array(eval(state_1['jobWaiting']))\n",
    "            activated_job_list_1 = eval(state_1['activatedJobList'])\n",
    "            isAction_1 = int(state_1['isAction'])\n",
    "            reward_1 = float(state_1['reward'])\n",
    "            averageLatency_1 = float(state_1['averageLatency'])\n",
    "            completeJobNum_1 = int(state_1['completeJobNum'])\n",
    "            sojournTime_1 = float(state_1['sojournTime'])\n",
    "\n",
    "            node_waiting_state_2 = np.array(eval(str(state_2['nodeState'])))\n",
    "            node_processing_state_2 = np.array(eval(state_2['nodeProcessing']))\n",
    "            link_state_2 = np.array(eval(state_2['linkWaiting']))\n",
    "            job_waiting_state_2 = np.array(eval(state_2['jobWaiting']))\n",
    "            activated_job_list_2 = eval(state_2['activatedJobList'])\n",
    "            isAction_2 = int(state_2['isAction'])\n",
    "            reward_2 = float(state_2['reward'])\n",
    "            averageLatency_2 = float(state_2['averageLatency'])\n",
    "            completeJobNum_2 = int(state_2['completeJobNum'])\n",
    "            sojournTime_2 = float(state_2['sojournTime'])\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "            writer.add_scalar(\"completeJobNum/train\", completeJobNum_2 ,step)\n",
    "            \n",
    "\n",
    "            # 이 timestep에서 발생한 모든 샘플에 똑같은 보상 적용.\n",
    "            if averageLatency_2 == -1:\n",
    "                reward_2 = 0\n",
    "            else:\n",
    "                reward_2 = completeJobNum_2\n",
    "            \n",
    "            writer.add_scalar(\"Reward/train\", reward_2, step)\n",
    "                \n",
    "            first_sample = True\n",
    "            if config[\"is_train\"] and len(pre_state_1) == 0:\n",
    "                for history in temp_history:\n",
    "                    history[3] = reward_2\n",
    "                    history[4] = network_state\n",
    "                    history[5] = job_waiting_state\n",
    "                    model.history.append(history)\n",
    "                    model.put_data(history)\n",
    "\n",
    "            model.history = model.history[-config[\"replay_buffer_size\"]:]\n",
    "            \n",
    "\n",
    "            temp_history = []\n",
    "\n",
    "            job_index = int(state_2['jobIndex'])\n",
    "\n",
    "            #print('sojourn time :', sojournTime)\n",
    "\n",
    "\n",
    "            node_state_1 = np.concatenate((node_waiting_state_1,node_processing_state_1) ,axis = 1)\n",
    "            node_state_1 = torch.tensor(node_state_1, dtype=torch.float)\n",
    "\n",
    "            node_state_2 = np.concatenate((node_waiting_state_2,node_processing_state_2) ,axis = 1)\n",
    "            node_state_2 = torch.tensor(node_state_2, dtype=torch.float)\n",
    "\n",
    "            #print(reward)\n",
    "\n",
    "            link_state_1 = torch.tensor(link_state_1, dtype=torch.float)\n",
    "            link_state_2 = torch.tensor(link_state_2, dtype=torch.float)\n",
    "\n",
    "            job_waiting_num = 0\n",
    "            job_waiting_queue = collections.deque()\n",
    "            for job in job_waiting_state_2:\n",
    "                if any(job): # 하나라도 0이 아닌 것 이 있으면 job이 있는것임.\n",
    "                    job_waiting_num += 1\n",
    "                    job_waiting_queue.append(job)\n",
    "            \n",
    "            job_waiting_state_1 = torch.tensor(job_waiting_state_1, dtype=torch.float).view(1, -1)\n",
    "            job_waiting_state_2 = torch.tensor(job_waiting_state_2, dtype=torch.float).view(1, -1)\n",
    "            # print(job_waiting_state)\n",
    "\n",
    "            network_state_1 = Data(x=node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "            network_state_2 = Data(x=node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "            network_state = [network_state_1.cuda(), network_state_2.cuda()]\n",
    "            job_waiting_state = [job_waiting_state_1.cuda(), job_waiting_state_2.cuda()]\n",
    "\n",
    "            pre_state_1 = state_1\n",
    "            pre_state_2 = state_2\n",
    "            \n",
    "            if average_reward_num == 0:\n",
    "                average_reward = reward_2\n",
    "                average_reward_num = 1\n",
    "            else:\n",
    "                average_reward = average_reward + (reward_2 - average_reward)/(average_reward_num + 1)\n",
    "                average_reward_num += 1\n",
    "                \n",
    "            if step > 1:\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    node_tag = \"node/\" + str(i) + \"/train\"\n",
    "                    writer.add_scalar(node_tag, node_selected_num[i], step)\n",
    "\n",
    "                writer.add_scalar(\"node/void/train\", void_selected_num, step)\n",
    "                    \n",
    "                node_selected_num = [0 for i in range(config[\"node_num\"])] # node selected num 초기화\n",
    "                void_selected_num = 0\n",
    "\n",
    "                if reward_2 != 0:\n",
    "                    with torch.no_grad():\n",
    "                        state = model.gnn([network_state, job_waiting_state])\n",
    "                        writer.add_scalar(\"Value/train\", torch.mean(model.v(state)), step)\n",
    "                \n",
    "\n",
    "                writer.flush()\n",
    "\n",
    "            \n",
    "            \n",
    "            # print(job_waiting_queue)\n",
    "            if job_waiting_num == 0:\n",
    "                isAction_2 = False\n",
    "                \n",
    "\n",
    "            if isAction_2:\n",
    "                job_idx = job_index\n",
    "                job = job_waiting_queue.popleft()\n",
    "                src = -1\n",
    "                dst = 1\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    if job[i] == -1:\n",
    "                        src = i\n",
    "                    if job[i] == 1:\n",
    "                        dst = i\n",
    "\n",
    "                if src == -1:\n",
    "                    src = dst\n",
    "                    \n",
    "                #print(f\"src : {src}, dst : {dst}\")\n",
    "                #print(job)\n",
    "                subtasks = job[config[\"node_num\"]:]\n",
    "                offloading_vector = []\n",
    "                temp_data = []\n",
    "                scheduling_start = False\n",
    "                # print(subtasks)\n",
    "                step += 1\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    feature = model.gnn([network_state, job_waiting_state])\n",
    "                    new_feature = feature.repeat(config[\"model_num\"], 1)\n",
    "                    prob, entropy, output = model.pi([new_feature, (torch.zeros(config[\"model_num\"], config[\"lstm_hidden_num\"]).cuda(), torch.zeros(config[\"model_num\"], config[\"lstm_hidden_num\"]).cuda())])\n",
    "\n",
    "                writer.add_scalar(\"Entropy/train\", entropy[0], step)\n",
    "                #print(f'prob : {prob}')\n",
    "\n",
    "                prob = prob.to(\"cpu\")\n",
    "                entropy = entropy.to(\"cpu\")\n",
    "                output = output.to(\"cpu\")\n",
    "\n",
    "                # isVoid = F.sigmoid(dists[modelNum].sample())\n",
    "\n",
    "                m = Categorical(prob) \n",
    "                nodes = m.sample()\n",
    "\n",
    "                node = nodes[0].item()\n",
    "\n",
    "                #print(f'node : {node}')\n",
    "                \n",
    "                # void action 실험용\n",
    "                # node = nodeNum \n",
    "                \n",
    "                \n",
    "                # void action 뽑으면 void만 업데이트\n",
    "                if node == config[\"node_num\"] and not scheduling_start: \n",
    "                    prob[0] = torch.Tensor([0] * config[\"node_num\"] + [1.0])\n",
    "                    action_mask = [int(not scheduling_start) if i == node else int(scheduling_start) for i in range(config[\"node_num\"] + 1)]\n",
    "\n",
    "                    temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, 0, \n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]],\n",
    "                        prob[0][node].item(), \n",
    "                        0, action_mask, 0]\n",
    "                    )\n",
    "\n",
    "                    sendOmnetMessage(\"void\")\n",
    "\n",
    "                    #print(\"action finish.\")\n",
    "                    \n",
    "                    if getOmnetMessage() == \"ok\":\n",
    "                        void_selected_num += 1\n",
    "\n",
    "                else:\n",
    "                    scheduling_start = True\n",
    "\n",
    "                if scheduling_start:\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        feature = model.gnn([network_state, job_waiting_state])\n",
    "                        new_feature = feature.repeat(config[\"model_num\"], 1)\n",
    "                        prob, entropy, output = model.pi([new_feature, (torch.zeros(config[\"model_num\"], config[\"lstm_hidden_num\"]).cuda(), torch.zeros(config[\"model_num\"], config[\"lstm_hidden_num\"]).cuda())])\n",
    "\n",
    "                    output = output[:, 0:-1]\n",
    "\n",
    "                    prob = prob.to(\"cpu\")\n",
    "                    entropy = entropy.to(\"cpu\")\n",
    "                    output = output.to(\"cpu\")\n",
    "\n",
    "                    prob = F.softmax(output, dim=0)\n",
    "                    prob = torch.concat([prob, torch.zeros(config[\"model_num\"], 1)], dim =1)\n",
    "\n",
    "                    m = Categorical(prob)\n",
    "                    nodes = m.sample()\n",
    "                    action_mask = [1] * config[\"node_num\"] + [0]\n",
    "\n",
    "                    for index in range(config[\"model_num\"]):\n",
    "\n",
    "                        node = nodes[index].item()\n",
    "\n",
    "                        temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, -1, \n",
    "                        [-1, -1], \n",
    "                        [-1, -1],\n",
    "                        prob[index][node].item(), \n",
    "                        0, action_mask, index]\n",
    "                        )\n",
    "\n",
    "                        offloading_vector.append(node)\n",
    "                        node_selected_num[node] += 1\n",
    "                    \n",
    "                if len(offloading_vector) != 0: # for문을 다 돌면 -> void action 안뽑으면\n",
    "                    # print(offloading_vector)\n",
    "                    msg = str(offloading_vector)\n",
    "                    sendOmnetMessage(msg)\n",
    "                    \n",
    "                    #print(\"action finish.\")\n",
    "                    if(getOmnetMessage() == \"ok\"):\n",
    "                        pass\n",
    "\n",
    "        elif msg == \"stop\":\n",
    "            \n",
    "            sendOmnetMessage(\"ok\")\n",
    "            pre_state_1 = {}\n",
    "            pre_state_2 = {}\n",
    "            \n",
    "        elif msg == \"episode_finish\":\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            episodic_reward = getOmnetMessage()\n",
    "            episodic_reward = json.loads(episodic_reward)\n",
    "            \n",
    "            finish_num = float(episodic_reward['reward'])\n",
    "            complete_num = int(episodic_reward['completNum'])\n",
    "            average_latency = float(episodic_reward['averageLatency'])\n",
    "\n",
    "            normalized_finish_num = model.return_normalize_reward(finish_num)\n",
    "            \n",
    "            writer.add_scalar(\"EpisodicReward/train\", finish_num, episode)\n",
    "            writer.add_scalar(\"NormalizedEpisodicReward/train\", normalized_finish_num, episode)\n",
    "            writer.add_scalar(\"CompleteNum/train\", complete_num, episode)\n",
    "            writer.add_scalar(\"averageLatency/train\", average_latency ,episode)\n",
    "\n",
    "            episode += 1\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            if finish_num > max_reward:\n",
    "                modelPathName = config[\"path_name\"] + \"/max_model.pth\"\n",
    "                torch.save(model.state_dict(), modelPathName)\n",
    "                max_reward = finish_num\n",
    "\n",
    "            writer.add_scalar(\"AverageReward/train\", average_reward, step)\n",
    "            average_reward = 0\n",
    "            average_reward_num = 0\n",
    "\n",
    "            if config[\"is_train\"]:\n",
    "            \n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training....\")\n",
    "                model.train_net()\n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training replay buffer....\")\n",
    "                model.train_net_history()\n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                if episode % 100 == 0:\n",
    "                    modelPathName = config[\"path_name\"] + f\"/model_{episode}.pth\"\n",
    "                    torch.save(model.state_dict(), modelPathName)\n",
    "\n",
    "                    time.sleep(10)\n",
    "                \n",
    "                modelPathName = config[\"path_name\"] + \"/model.pth\"\n",
    "                torch.save(model.state_dict(), modelPathName)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPE_NAME = \"\\\\\\\\.\\\\pipe\\\\worker1\"\n",
    "BUFFER_SIZE = 200000\n",
    "\n",
    "try:\n",
    "    pipe = win32pipe.CreateNamedPipe(\n",
    "        PIPE_NAME,\n",
    "        win32pipe.PIPE_ACCESS_DUPLEX,\n",
    "        win32pipe.PIPE_TYPE_MESSAGE | win32pipe.PIPE_READMODE_MESSAGE | win32pipe.PIPE_WAIT,\n",
    "        1,\n",
    "        BUFFER_SIZE,\n",
    "        BUFFER_SIZE,\n",
    "        0,\n",
    "        None\n",
    "    )    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "win32pipe.ConnectNamedPipe(pipe, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = getOmnetMessage()\n",
    "networkInfo = json.loads(initial_message)\n",
    "\n",
    "modelNum = int(networkInfo['modelNum'])\n",
    "availableJobNum = int(networkInfo['availableJobNum'])\n",
    "nodeNum = int(networkInfo['nodeNum'])\n",
    "jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "adjacency = eval(networkInfo['adjacencyList'])\n",
    "episode_length = int(networkInfo['episode_length'])\n",
    "node_capacity = networkInfo['node_capacity']\n",
    "job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "reward_weight = 1/modelNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_test\")\n",
    "folderList = glob.glob(\"history*\")\n",
    "\n",
    "pathName = \"history\" + str(len(folderList))\n",
    "\n",
    "print(pathName)\n",
    "\n",
    "os.mkdir(pathName)\n",
    "\n",
    "writer = SummaryWriter(pathName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 초기화 완료\n",
      "\n",
      "    노드 개수 : 10\n",
      "    네트워크 최대 job 개수 : 5\n",
      "    job 대기 가능 개수 : 15\n",
      "    최대 subtask 개수 : 3\n",
      "    인접 리스트 : [[0, 1, 0, 2, 0, 3, 0, 6, 0, 8, 1, 3, 1, 4, 1, 5, 1, 7, 1, 8, 3, 4, 4, 5, 4, 6, 4, 7, 5, 9, 7, 9], [1, 0, 2, 0, 3, 0, 6, 0, 8, 0, 3, 1, 4, 1, 5, 1, 7, 1, 8, 1, 4, 3, 5, 4, 6, 4, 7, 4, 9, 5, 9, 7]]\n",
      "    node_feature_num : 30\n",
      "    queue_feature_num : 195\n",
      "    episode_length : 100\n",
      "    node_capacity : 0.030000, 0.090000\n",
      "    entropy_weight : 0.1\n",
      "    reward_weight : 0.3333333333333333\n",
      "    job_generate_rate : 30\n",
      "    \n",
      "[2023-01-18 03:32:44 PM] training....\n",
      "[2023-01-18 03:32:44 PM] training complete\n",
      "[2023-01-18 03:32:44 PM] training replay buffer....\n",
      "[2023-01-18 03:32:45 PM] training complete\n",
      "[2023-01-18 03:32:52 PM] training....\n",
      "[2023-01-18 03:32:52 PM] training complete\n",
      "[2023-01-18 03:32:52 PM] training replay buffer....\n",
      "[2023-01-18 03:32:54 PM] training complete\n",
      "[2023-01-18 03:33:01 PM] training....\n",
      "[2023-01-18 03:33:01 PM] training complete\n",
      "[2023-01-18 03:33:01 PM] training replay buffer....\n",
      "[2023-01-18 03:33:02 PM] training complete\n",
      "[2023-01-18 03:33:09 PM] training....\n",
      "[2023-01-18 03:33:09 PM] training complete\n",
      "[2023-01-18 03:33:09 PM] training replay buffer....\n",
      "[2023-01-18 03:33:10 PM] training complete\n",
      "[2023-01-18 03:33:17 PM] training....\n",
      "[2023-01-18 03:33:17 PM] training complete\n",
      "[2023-01-18 03:33:17 PM] training replay buffer....\n",
      "[2023-01-18 03:33:18 PM] training complete\n",
      "[2023-01-18 03:33:24 PM] training....\n",
      "[2023-01-18 03:33:24 PM] training complete\n",
      "[2023-01-18 03:33:24 PM] training replay buffer....\n",
      "[2023-01-18 03:33:25 PM] training complete\n",
      "[2023-01-18 03:33:31 PM] training....\n",
      "[2023-01-18 03:33:31 PM] training complete\n",
      "[2023-01-18 03:33:31 PM] training replay buffer....\n",
      "[2023-01-18 03:33:32 PM] training complete\n",
      "[2023-01-18 03:33:38 PM] training....\n",
      "[2023-01-18 03:33:38 PM] training complete\n",
      "[2023-01-18 03:33:38 PM] training replay buffer....\n",
      "[2023-01-18 03:33:39 PM] training complete\n",
      "[2023-01-18 03:33:46 PM] training....\n",
      "[2023-01-18 03:33:46 PM] training complete\n",
      "[2023-01-18 03:33:46 PM] training replay buffer....\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sendOmnetMessage(\"init\") # 입력 끝나면 omnet에 전송\n",
    "    print(\"네트워크 초기화 완료\")\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\"         : 0.0001,\n",
    "        \"gamma\"                 : 0.97,\n",
    "        \"entropy_weight\"        : 0.1,\n",
    "        \"lambda\"                : 0.8,\n",
    "        \"eps_clip\"              : 0.2,\n",
    "        \"batch_size\"            : 128,\n",
    "        \"loss_coef\"             : 0.5,\n",
    "        \"job_generate_rate\"     : 0.003,\n",
    "        \"is_train\"              : True,\n",
    "        \"replay_buffer_size\"    : 10000,\n",
    "        \"history_learning_time\" : 3,\n",
    "        \"current_learning_time\" : 0,\n",
    "        \"node_feature_num\"      : 2 * (modelNum * availableJobNum),\n",
    "        \"queue_feature_num\"     : (nodeNum + modelNum) * jobWaitingLength,\n",
    "        \"hidden_feature_num\"    : 10*(node_feature_num + queue_feature_num),\n",
    "        \"reward_weight\"         : 1.0/modelNum,\n",
    "        \"node_num\"              : nodeNum,\n",
    "        \"model_num\"             : modelNum,\n",
    "        \"lstm_hidden_num\"       : 10,\n",
    "        \"cpu_load_balance_time\" : 0.1,\n",
    "        \"network_info\"          : networkInfo,\n",
    "        \"path_name\"             : pathName,\n",
    "    }\n",
    "\n",
    "    main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnetTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12c9d4573c12dd45eabff63c44badb6fcd2b70b85de11a1a1b2c23254cbf5db5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
