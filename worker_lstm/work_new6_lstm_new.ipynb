{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mmap\n",
    "import time\n",
    "from time import strftime, localtime\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import import_ipynb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import sys \n",
    "import win32pipe, win32file, pywintypes\n",
    "\n",
    "from actor_no_readout import actor_network\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendOmnetMessage(msg):\n",
    "    win32file.WriteFile(pipe, msg.encode('utf-8'))\n",
    "    \n",
    "def getOmnetMessage():\n",
    "    response_byte = win32file.ReadFile(pipe, BUFFER_SIZE)\n",
    "    response_str = response_byte[1].decode('utf-8')\n",
    "    return response_str\n",
    "\n",
    "def closePipe():\n",
    "    win32file.CloseHandle(pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험 정보 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordExpInfo(config):\n",
    "\n",
    "    networkInfo = config[\"network_info\"]\n",
    "\n",
    "    modelNum = int(networkInfo['modelNum'])\n",
    "    availableJobNum = int(networkInfo['availableJobNum'])\n",
    "    nodeNum = int(networkInfo['nodeNum'])\n",
    "    jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "    adjacency = eval(networkInfo['adjacencyList'])\n",
    "    episode_length = int(networkInfo['episode_length'])\n",
    "    node_capacity = networkInfo['node_capacity']\n",
    "    job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "    node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "    queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "    hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "    reward_weight = 1/modelNum\n",
    "    entropy_weight = config[\"entropy_weight\"]\n",
    "    \n",
    "    info = f\"\"\"\n",
    "    노드 개수 : {nodeNum}\n",
    "    네트워크 최대 job 개수 : {availableJobNum}\n",
    "    job 대기 가능 개수 : {jobWaitingLength}\n",
    "    최대 subtask 개수 : {modelNum}\n",
    "    인접 리스트 : {adjacency}\n",
    "    node_feature_num : {node_feature_num}\n",
    "    queue_feature_num : {queue_feature_num}\n",
    "    episode_length : {episode_length}\n",
    "    node_capacity : {node_capacity}\n",
    "    entropy_weight : {entropy_weight}\n",
    "    reward_weight : {reward_weight}\n",
    "    job_generate_rate : {job_generate_rate}\n",
    "    \"\"\"\n",
    "    print(info)\n",
    "\n",
    "    with open(f'{config[\"path_name\"]}/info.txt', 'w') as f:\n",
    "        f.write(f'{info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "def main(config):\n",
    "    global adjacency, writer\n",
    "\n",
    "    recordExpInfo(config)\n",
    "    \n",
    "    model = actor_network(config)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(total_params)\n",
    "    # model.load_state_dict(torch.load(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_reward/history0/model.pth\"))\n",
    "    # model.load_state_dict(torch.load(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_num_test_same_env/history17/model_1100.pth\"))\n",
    "    reward_history = []\n",
    "    v_history = []\n",
    "\n",
    "    adjacency = torch.tensor(adjacency, dtype=torch.long)\n",
    "\n",
    "    step = 1\n",
    "    episode = 1\n",
    "\n",
    "    max_reward = 0\n",
    "\n",
    "    average_reward = 0\n",
    "    average_reward_num = 0\n",
    "\n",
    "    temp_history = deque([])\n",
    "    episode_history = []\n",
    "    rewards = []\n",
    "\n",
    "    isStop = False\n",
    "    node_selected_num = [0 for i in range(config[\"node_num\"])]\n",
    "    void_selected_num = 0\n",
    "\n",
    "    pre_state_1 = {}\n",
    "    pre_state_2 = {}\n",
    "\n",
    "    void_mask = [0] * config[\"node_num\"] + [1]\n",
    "    unvoid_mask = [1] * config[\"node_num\"] + [0]\n",
    "\n",
    "    episode_total_reward = 0\n",
    "    hidden = (torch.zeros(1, 1, config[\"lstm_hidden_num\"]), torch.zeros(1, 1, config[\"lstm_hidden_num\"]))\n",
    "    \n",
    "    while True:\n",
    "        # time.sleep(config[\"cpu_load_balance_time\"])\n",
    "        \n",
    "        model = model.to('cpu')\n",
    "        model.eval()\n",
    "        msg = getOmnetMessage()\n",
    "        \n",
    "        if msg == \"action\": # omnet의 메세지, state 받으면 됨\n",
    "            sendOmnetMessage(\"ok\")\n",
    "            state_1 = getOmnetMessage()\n",
    "            state_2 = getOmnetMessage()\n",
    "\n",
    "            if len(state_1) == 0:\n",
    "                state_1 = state_2\n",
    "            \n",
    "\n",
    "            if len(pre_state_1) == 0: # action 시작\n",
    "                state_1 = json.loads(state_1) # state 받았으므로 action 하면됨.\n",
    "                state_2 = json.loads(state_2) # state 받았으므로 action 하면됨.\n",
    "                \n",
    "            else:\n",
    "                state_1 = json.loads(state_1)\n",
    "                pre_state_1['jobWaiting'] = state_1['jobWaiting']\n",
    "                pre_state_1['sojournTime'] = state_1['sojournTime']\n",
    "                state_1 = pre_state_1\n",
    "\n",
    "                state_2 = json.loads(state_2)\n",
    "                pre_state_2['jobWaiting'] = state_2['jobWaiting']\n",
    "                pre_state_2['sojournTime'] = state_2['sojournTime']\n",
    "                state_2 = pre_state_2\n",
    "            \n",
    "            sendOmnetMessage(\"ok\") # 답장\n",
    "\n",
    "            \n",
    "            node_waiting_state_1 = torch.tensor(eval(str(state_1['nodeState'])), dtype=torch.float)\n",
    "            node_processing_state_1 = torch.tensor(eval(state_1['nodeProcessing']), dtype=torch.float)\n",
    "            link_state_1 = torch.tensor(eval(state_1['linkWaiting']), dtype=torch.float)\n",
    "            job_waiting_state_1 = torch.tensor(eval(state_1['jobWaiting']), dtype=torch.float)\n",
    "            activated_job_list_1 = eval(state_1['activatedJobList'])\n",
    "            isAction_1 = int(state_1['isAction'])\n",
    "            reward_1 = float(state_1['reward'])\n",
    "            averageLatency_1 = float(state_1['averageLatency'])\n",
    "            completeJobNum_1 = int(state_1['completeJobNum'])\n",
    "            sojournTime_1 = float(state_1['sojournTime'])\n",
    "            #startLatency_1 = float(state_1[\"startLatency\"])\n",
    "\n",
    "            node_waiting_state_2 = torch.tensor(eval(str(state_2['nodeState'])), dtype=torch.float)\n",
    "            node_processing_state_2 = torch.tensor(eval(state_2['nodeProcessing']), dtype=torch.float)\n",
    "            link_state_2 = torch.tensor(eval(state_2['linkWaiting']), dtype=torch.float)\n",
    "            job_waiting_state_2 = torch.tensor(eval(state_2['jobWaiting']), dtype=torch.float)\n",
    "            activated_job_list_2 = eval(state_2['activatedJobList'])\n",
    "            isAction_2 = int(state_2['isAction'])\n",
    "            reward_2 = float(state_2['reward'])\n",
    "            averageLatency_2 = float(state_2['averageLatency'])\n",
    "            completeJobNum_2 = int(state_2['completeJobNum'])\n",
    "            sojournTime_2 = float(state_2['sojournTime'])\n",
    "            #startLatency_2 = float(state_2[\"startLatency\"])\n",
    "\n",
    "            # print(reward_2)\n",
    "\n",
    "\n",
    "\n",
    "            # node_waiting_state_2 = torch.tensor(eval(str(state_1['nodeState'])), dtype=torch.float)\n",
    "            # node_processing_state_2 = torch.tensor(eval(state_1['nodeProcessing']), dtype=torch.float)\n",
    "            # link_state_2 = torch.tensor(eval(state_1['linkWaiting']), dtype=torch.float)\n",
    "            # job_waiting_state_2 = torch.tensor(eval(state_1['jobWaiting']), dtype=torch.float)\n",
    "            # activated_job_list_2 = eval(state_1['activatedJobList'])\n",
    "            # isAction_2 = int(state_1['isAction'])\n",
    "            # reward_2 = float(state_1['reward'])\n",
    "            # averageLatency_2 = float(state_1['averageLatency'])\n",
    "            # completeJobNum_2 = int(state_1['completeJobNum'])\n",
    "            # sojournTime_2 = float(state_1['sojournTime'])\n",
    "\n",
    "            writer.add_scalar(\"completeJobNum/train\", completeJobNum_2 ,step)\n",
    "\n",
    "            #print(node_waiting_state_2)\n",
    "            #print(node_processing_state_2)\n",
    "            \n",
    "\n",
    "            # # 이 timestep에서 발생한 모든 샘플에 똑같은 보상 적용.\n",
    "            # if averageLatency_2 == -1:\n",
    "            #     reward_2 = 0\n",
    "            # else:\n",
    "            #     reward_2 = completeJobNum_2\n",
    "\n",
    "            # reward_2 = startLatency_2 * 100\n",
    "\n",
    "            #print(reward_2)\n",
    "            \n",
    "            writer.add_scalar(\"Reward/train\", reward_2, step)\n",
    "\n",
    "            episode_total_reward += reward_2\n",
    "\n",
    "            if reward_2 != 0:\n",
    "                rewards.append(reward_2)\n",
    "                \n",
    "            first_sample = True\n",
    "            if config[\"is_train\"] and len(pre_state_1) == 0:\n",
    "                if temp_history:\n",
    "                    temp_history[-1][3] = reward_2\n",
    "                    temp_history[-1][4] = network_state\n",
    "                    temp_history[-1][5] = job_waiting_state\n",
    "\n",
    "                while temp_history:\n",
    "                    history = temp_history.popleft()\n",
    "                    \n",
    "                    # model.history.append(history)\n",
    "                    episode_history.append(history)\n",
    "                    model.put_data(history)\n",
    "\n",
    "            \n",
    "\n",
    "            temp_history = deque([])\n",
    "\n",
    "            job_index = int(state_2['jobIndex'])\n",
    "\n",
    "            #print('sojourn time :', sojournTime)\n",
    "\n",
    "\n",
    "            # node_state_1 = np.concatenate((node_waiting_state_1,node_processing_state_1) ,axis = 1)\n",
    "            #node_state_1 = torch.concat([node_waiting_state_1, node_processing_state_1], dim=1)\n",
    "            node_state_1 = node_waiting_state_1\n",
    "            # node_state_2 = np.concatenate((node_waiting_state_2,node_processing_state_2) ,axis = 1)\n",
    "            #node_state_2 = torch.concat([node_waiting_state_2, node_processing_state_2], dim=1)\n",
    "            node_state_2 = node_waiting_state_2\n",
    "\n",
    "            #print(reward)\n",
    "\n",
    "            # link_state_1 = torch.tensor(link_state_1, dtype=torch.float)\n",
    "            # link_state_2 = torch.tensor(link_state_2, dtype=torch.float)\n",
    "\n",
    "            job_waiting_num = 0\n",
    "            job_waiting_queue = deque()\n",
    "            for job in job_waiting_state_2:\n",
    "                if any(job): # 하나라도 0이 아닌 것 이 있으면 job이 있는것임.\n",
    "                    job_waiting_num += 1\n",
    "                    job_waiting_queue.append(job)\n",
    "            \n",
    "            job_waiting_state_1 = job_waiting_state_1.view(1, -1)\n",
    "            job_waiting_state_2 = job_waiting_state_2.view(1, -1)\n",
    "            # print(job_waiting_state)\n",
    "\n",
    "            network_state_1 = Data(x=node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "            network_state_2 = Data(x=node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "            network_state = [network_state_1, network_state_2]\n",
    "            job_waiting_state = [job_waiting_state_1, job_waiting_state_2]\n",
    "\n",
    "            pre_state_1 = state_1\n",
    "            pre_state_2 = state_2\n",
    "            \n",
    "            if average_reward_num == 0:\n",
    "                average_reward = reward_2\n",
    "                average_reward_num = 1\n",
    "            else:\n",
    "                average_reward = average_reward + (reward_2 - average_reward)/(average_reward_num + 1)\n",
    "                average_reward_num += 1\n",
    "                \n",
    "            if step > 1:\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    node_tag = \"node/\" + str(i) + \"/train\"\n",
    "                    writer.add_scalar(node_tag, node_selected_num[i], step)\n",
    "\n",
    "                writer.add_scalar(\"node/void/train\", void_selected_num, step)\n",
    "                    \n",
    "                node_selected_num = [0 for i in range(config[\"node_num\"])] # node selected num 초기화\n",
    "                void_selected_num = 0\n",
    "\n",
    "                if reward_2 != 0:\n",
    "                    with torch.no_grad():\n",
    "                        state = model.gnn([network_state, job_waiting_state])\n",
    "                        writer.add_scalar(\"Value/train\", torch.mean(model.v(state)), step)\n",
    "                \n",
    "\n",
    "                writer.flush()\n",
    "\n",
    "            \n",
    "            \n",
    "            # print(job_waiting_queue)\n",
    "            if job_waiting_num == 0:\n",
    "                isAction_2 = False\n",
    "                \n",
    "\n",
    "            if isAction_2:\n",
    "                \"\"\"if step % config[\"T_horizon\"] == 0:\n",
    "\n",
    "                    print(\"hello\")\n",
    "\n",
    "                    if config[\"is_train\"]:\n",
    "                        if episode % 100 == 0:\n",
    "                            tm = localtime(time.time())\n",
    "                            time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                            print(f\"[{time_string}] training....\")\n",
    "                        model.train_net()\n",
    "                        if episode % 100 == 0:\n",
    "                            tm = localtime(time.time())\n",
    "                            time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                            print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                        model = model.cpu()\"\"\"\n",
    "\n",
    "\n",
    "                job_idx = job_index\n",
    "                job = job_waiting_queue.popleft()\n",
    "                src = -1\n",
    "                dst = 1\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    if job[i] == -1:\n",
    "                        src = i\n",
    "                    if job[i] == 1:\n",
    "                        dst = i\n",
    "\n",
    "                if src == -1:\n",
    "                    src = dst\n",
    "                    \n",
    "                #print(f\"src : {src}, dst : {dst}\")\n",
    "                #print(job)\n",
    "                subtasks = job[config[\"node_num\"]:]\n",
    "                offloading_vector = []\n",
    "                temp_data = []\n",
    "                scheduling_start = False\n",
    "                # print(subtasks)\n",
    "                step += 1\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    feature = model.gnn([network_state, job_waiting_state])\n",
    "                    feature = F.normalize(feature, dim=1)\n",
    "                    new_feature = feature.unsqueeze(0)\n",
    "                    first_prob, entropy, output, hidden = model.pi([new_feature, hidden])\n",
    "\n",
    "                writer.add_scalar(\"Entropy/train\", torch.mean(entropy).item(), step)\n",
    "                #print(f'prob : {prob}')\n",
    "\n",
    "                # isVoid = F.sigmoid(dists[modelNum].sample())\n",
    "\n",
    "                m = Categorical(first_prob[0][0]) # 첫 번째 batch의 첫 번째 node+void개의 확률들\n",
    "                nodes = m.sample()\n",
    "\n",
    "                node = nodes.item()\n",
    "\n",
    "                #print(f'node : {node}')\n",
    "                \n",
    "                # void action 실험용\n",
    "                # node = nodeNum \n",
    "                \n",
    "                \n",
    "                # void action 뽑으면 void만 업데이트\n",
    "                if node == config[\"node_num\"] and not scheduling_start: \n",
    "                    action_mask = void_mask\n",
    "\n",
    "                    temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, 0, \n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]],\n",
    "                        1, \n",
    "                        0, action_mask, 0]\n",
    "                    )\n",
    "\n",
    "                    sendOmnetMessage(\"void\")\n",
    "\n",
    "                    #print(\"action finish.\")\n",
    "                    \n",
    "                    if getOmnetMessage() == \"ok\":\n",
    "                        void_selected_num += 1\n",
    "\n",
    "                else:\n",
    "                    scheduling_start = True\n",
    "\n",
    "                if scheduling_start:\n",
    "                    \n",
    "                    if random.random() > config[\"imitation_probability\"]:\n",
    "                            config[\"our\"] = True\n",
    "                    else:\n",
    "                        config[\"our\"] = False\n",
    "                    \n",
    "\n",
    "                    for sub_index in range(config[\"model_num\"]):\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            feature = model.gnn([network_state, job_waiting_state])\n",
    "                            feature = F.normalize(feature, dim=1)\n",
    "                            new_feature = feature.unsqueeze(0)\n",
    "                            prob, entropy, output, hidden = model.pi([new_feature, hidden])\n",
    "                            # print(prob)\n",
    "\n",
    "                        writer.add_scalar(\"Entropy/train\", torch.mean(entropy).item(), step)\n",
    "\n",
    "                        output = output[:, :, 0:-1].squeeze(0)\n",
    "\n",
    "                        prob = F.softmax(output, dim=1)\n",
    "                        prob = torch.concat([prob, torch.zeros(1, 1)], dim=1)\n",
    "\n",
    "                        m = Categorical(prob)\n",
    "                        nodes = m.sample()\n",
    "                        action_mask = unvoid_mask\n",
    "\n",
    "\n",
    "                        if config[\"our\"]:\n",
    "                            node = nodes[0].item()\n",
    "                        else:\n",
    "                            node = torch.argmin(node_waiting_state_2[:,0]).item()\n",
    "\n",
    "                        next_node_state_2 = node_state_1.clone() # node_state_1을 node_state2로 복사\n",
    "\n",
    "                        #print(node_state_1)\n",
    "\n",
    "                        next_node_state_1 = node_state_1.clone()\n",
    "                        next_node_state_1[node][3] += subtasks[sub_index]\n",
    "                        next_node_state_1[node][1] = next_node_state_1[node][3] / next_node_state_1[node][2]\n",
    "\n",
    "                        next_network_state_1 = Data(x=next_node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "                        next_network_state_2 = Data(x=next_node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "                        next_network_state = [next_network_state_1, next_network_state_2]\n",
    "                        # allJobWait, allJobWaitTime, power, jobRemain\n",
    "                        next_job_waiting_state = [job_waiting_state_1, job_waiting_state_2]\n",
    "\n",
    "                        temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, 0, \n",
    "                        next_network_state, \n",
    "                        next_job_waiting_state,\n",
    "                        prob[0][node].item(),\n",
    "                        0, action_mask, 0]\n",
    "                        )\n",
    "\n",
    "                        offloading_vector.append(node)\n",
    "                        node_selected_num[node] += 1\n",
    "\n",
    "                        node_state_1 = next_node_state_1.clone()\n",
    "                        node_state_2 = next_node_state_2.clone()\n",
    "\n",
    "                        network_state_1 = Data(x=node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "                        network_state_2 = Data(x=node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "                        network_state = [network_state_1, network_state_2]\n",
    "                        job_waiting_state = next_job_waiting_state\n",
    "\n",
    "                if len(offloading_vector) != 0: # for문을 다 돌면 -> void action 안뽑으면\n",
    "                    # print(offloading_vector)\n",
    "                    msg = str(offloading_vector)\n",
    "                    sendOmnetMessage(msg)\n",
    "                    \n",
    "                    #print(\"action finish.\")\n",
    "                    if(getOmnetMessage() == \"ok\"):\n",
    "                        pass\n",
    "\n",
    "        elif msg == \"stop\":\n",
    "            \n",
    "            sendOmnetMessage(\"ok\")\n",
    "            pre_state_1 = {}\n",
    "            pre_state_2 = {}\n",
    "            \n",
    "        elif msg == \"episode_finish\":\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            # print(len(model.history))\n",
    "\n",
    "            mean = np.mean(rewards)\n",
    "            std = np.std(rewards)\n",
    "\n",
    "            #print(mean)\n",
    "            #print(std)\n",
    "            #print(rewards)\n",
    "\n",
    "            #for i in range(len(episode_history)):\n",
    "            #    if episode_history[i][3] != 0:\n",
    "            #        episode_history[i][3] = (episode_history[i][3] - mean) / (std + 1e-10)\n",
    "            #        #print((episode_history[i][3] - mean) / (std + 1e-10))\n",
    "\n",
    "            rewards = []\n",
    "\n",
    "\n",
    "            model.history.append(episode_history)\n",
    "            #aaaa = [episode_history[i][2] for i in range(len(episode_history))]\n",
    "            #print(len(aaaa))\n",
    "            #print(aaaa)\n",
    "            #rrrr = [episode_history[i][3] for i in range(len(episode_history))]\n",
    "            #print(len(rrrr))\n",
    "            #print(rrrr)\n",
    "            model.data = episode_history[:]\n",
    "            episode_history = []\n",
    "\n",
    "            episodic_reward = getOmnetMessage()\n",
    "            episodic_reward = json.loads(episodic_reward)\n",
    "            \n",
    "            finish_num = float(episodic_reward['reward'])\n",
    "            complete_num = int(episodic_reward['completNum'])\n",
    "            average_latency = float(episodic_reward['averageLatency'])\n",
    "            jitter = episodic_reward['jitter']\n",
    "            jitterMake = episodic_reward['jitterMake']\n",
    "            #print(list(map(float, jitter.strip().split(\" \"))))\n",
    "            #print(list(map(float, jitterMake.strip().split(\" \"))))\n",
    "\n",
    "            normalized_finish_num = model.return_normalize_reward(finish_num)\n",
    "            \n",
    "            writer.add_scalar(\"EpisodicReward/train\", finish_num, episode)\n",
    "            writer.add_scalar(\"NormalizedEpisodicReward/train\", normalized_finish_num, episode)\n",
    "            writer.add_scalar(\"CompleteNum/train\", complete_num, episode)\n",
    "            writer.add_scalar(\"averageLatency/train\", average_latency ,episode)\n",
    "\n",
    "            \n",
    "\n",
    "            episode_total_reward += complete_num\n",
    "\n",
    "            writer.add_scalar(\"episode_total_reward/train\", episode_total_reward, episode)\n",
    "\n",
    "            episode_total_reward = 0\n",
    "            hidden = (torch.zeros(1, 1, config[\"lstm_hidden_num\"]), torch.zeros(1, 1, config[\"lstm_hidden_num\"]))\n",
    "\n",
    "            episode += 1\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            config[\"entropy_weight\"] = max(0.0001, config[\"entropy_weight\"] * config[\"entropy_gamma\"])\n",
    "            config[\"imitation_probability\"] = max(config[\"imitation_gamma\"] * config[\"imitation_probability\"], 0.2)\n",
    "\n",
    "            if finish_num > max_reward:\n",
    "                modelPathName = config[\"path_name\"] + \"/max_model.pth\"\n",
    "                torch.save(model.state_dict(), modelPathName)\n",
    "                max_reward = finish_num\n",
    "\n",
    "            writer.add_scalar(\"AverageReward/train\", average_reward, step)\n",
    "            average_reward = 0\n",
    "            average_reward_num = 0\n",
    "\n",
    "            if config[\"is_train\"]:\n",
    "                \n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training....\")\n",
    "                model.train_net()\n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training replay buffer....\")\n",
    "                model.train_net_history()\n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                model.clear_data()\n",
    "\n",
    "                if episode % 100 == 0:\n",
    "                    modelPathName = config[\"path_name\"] + \"/model.pth\"\n",
    "                    torch.save(model.state_dict(), modelPathName)\n",
    "                    modelPathName = config[\"path_name\"] + f\"/model_{episode}.pth\"\n",
    "                    torch.save(model.state_dict(), modelPathName)\n",
    "\n",
    "                    time.sleep(10)\n",
    "\n",
    "                model.eval()\n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPE_NAME = \"\\\\\\\\.\\\\pipe\\\\worker_right_latency_sub2\"\n",
    "BUFFER_SIZE = 200000\n",
    "\n",
    "try:\n",
    "    pipe = win32pipe.CreateNamedPipe(\n",
    "        PIPE_NAME,\n",
    "        win32pipe.PIPE_ACCESS_DUPLEX,\n",
    "        win32pipe.PIPE_TYPE_MESSAGE | win32pipe.PIPE_READMODE_MESSAGE | win32pipe.PIPE_WAIT,\n",
    "        1,\n",
    "        BUFFER_SIZE,\n",
    "        BUFFER_SIZE,\n",
    "        0,\n",
    "        None\n",
    "    )    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "win32pipe.ConnectNamedPipe(pipe, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = getOmnetMessage()\n",
    "networkInfo = json.loads(initial_message)\n",
    "\n",
    "modelNum = int(networkInfo['modelNum'])\n",
    "availableJobNum = int(networkInfo['availableJobNum'])\n",
    "nodeNum = int(networkInfo['nodeNum'])\n",
    "jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "adjacency = eval(networkInfo['adjacencyList'])\n",
    "episode_length = int(networkInfo['episode_length'])\n",
    "node_capacity = networkInfo['node_capacity']\n",
    "job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "reward_weight = 1/modelNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_reward\")\n",
    "folderList = glob.glob(\"history*\")\n",
    "\n",
    "pathName = \"history\" + str(len(folderList))\n",
    "\n",
    "print(pathName)\n",
    "\n",
    "os.mkdir(pathName)\n",
    "\n",
    "writer = SummaryWriter(pathName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 초기화 완료\n",
      "\n",
      "    노드 개수 : 5\n",
      "    네트워크 최대 job 개수 : 5\n",
      "    job 대기 가능 개수 : 15\n",
      "    최대 subtask 개수 : 3\n",
      "    인접 리스트 : [[0, 1, 0, 2, 1, 2, 1, 3, 2, 3, 2, 4, 3, 4], [1, 0, 2, 0, 2, 1, 3, 1, 3, 2, 4, 2, 4, 3]]\n",
      "    node_feature_num : 30\n",
      "    queue_feature_num : 120\n",
      "    episode_length : 500\n",
      "    node_capacity : 0.100000, 0.300000\n",
      "    entropy_weight : 1e-05\n",
      "    reward_weight : 0.3333333333333333\n",
      "    job_generate_rate : 2\n",
      "    \n",
      "177047\n",
      "[2023-04-25 04:44:18 PM] training....\n",
      "[2023-04-25 04:44:19 PM] training complete\n",
      "[2023-04-25 04:44:19 PM] training replay buffer....\n",
      "[2023-04-25 04:44:19 PM] training complete\n",
      "[2023-04-25 04:46:08 PM] training....\n",
      "[2023-04-25 04:46:08 PM] training complete\n",
      "[2023-04-25 04:46:08 PM] training replay buffer....\n",
      "[2023-04-25 04:46:09 PM] training complete\n",
      "[2023-04-25 04:48:02 PM] training....\n",
      "[2023-04-25 04:48:02 PM] training complete\n",
      "[2023-04-25 04:48:02 PM] training replay buffer....\n",
      "[2023-04-25 04:48:02 PM] training complete\n",
      "[2023-04-25 04:49:51 PM] training....\n",
      "[2023-04-25 04:49:51 PM] training complete\n",
      "[2023-04-25 04:49:51 PM] training replay buffer....\n",
      "[2023-04-25 04:49:51 PM] training complete\n",
      "[2023-04-25 04:51:40 PM] training....\n",
      "[2023-04-25 04:51:40 PM] training complete\n",
      "[2023-04-25 04:51:40 PM] training replay buffer....\n",
      "[2023-04-25 04:51:40 PM] training complete\n",
      "[2023-04-25 04:53:30 PM] training....\n",
      "[2023-04-25 04:53:30 PM] training complete\n",
      "[2023-04-25 04:53:30 PM] training replay buffer....\n",
      "[2023-04-25 04:53:30 PM] training complete\n",
      "[2023-04-25 04:55:19 PM] training....\n",
      "[2023-04-25 04:55:19 PM] training complete\n",
      "[2023-04-25 04:55:19 PM] training replay buffer....\n",
      "[2023-04-25 04:55:19 PM] training complete\n",
      "[2023-04-25 04:57:07 PM] training....\n",
      "[2023-04-25 04:57:07 PM] training complete\n",
      "[2023-04-25 04:57:07 PM] training replay buffer....\n",
      "[2023-04-25 04:57:07 PM] training complete\n",
      "[2023-04-25 04:58:57 PM] training....\n",
      "[2023-04-25 04:58:58 PM] training complete\n",
      "[2023-04-25 04:58:58 PM] training replay buffer....\n",
      "[2023-04-25 04:58:58 PM] training complete\n",
      "[2023-04-25 05:00:49 PM] training....\n",
      "[2023-04-25 05:00:49 PM] training complete\n",
      "[2023-04-25 05:00:49 PM] training replay buffer....\n",
      "[2023-04-25 05:00:49 PM] training complete\n",
      "[2023-04-25 05:02:37 PM] training....\n",
      "[2023-04-25 05:02:37 PM] training complete\n",
      "[2023-04-25 05:02:37 PM] training replay buffer....\n",
      "[2023-04-25 05:02:37 PM] training complete\n",
      "[2023-04-25 05:04:30 PM] training....\n",
      "[2023-04-25 05:04:30 PM] training complete\n",
      "[2023-04-25 05:04:30 PM] training replay buffer....\n",
      "[2023-04-25 05:04:30 PM] training complete\n",
      "[2023-04-25 05:06:20 PM] training....\n",
      "[2023-04-25 05:06:20 PM] training complete\n",
      "[2023-04-25 05:06:20 PM] training replay buffer....\n",
      "[2023-04-25 05:06:20 PM] training complete\n",
      "[2023-04-25 05:08:09 PM] training....\n",
      "[2023-04-25 05:08:09 PM] training complete\n",
      "[2023-04-25 05:08:09 PM] training replay buffer....\n",
      "[2023-04-25 05:08:09 PM] training complete\n",
      "[2023-04-25 05:09:59 PM] training....\n",
      "[2023-04-25 05:09:59 PM] training complete\n",
      "[2023-04-25 05:09:59 PM] training replay buffer....\n",
      "[2023-04-25 05:09:59 PM] training complete\n",
      "[2023-04-25 05:11:49 PM] training....\n",
      "[2023-04-25 05:11:49 PM] training complete\n",
      "[2023-04-25 05:11:49 PM] training replay buffer....\n",
      "[2023-04-25 05:11:49 PM] training complete\n",
      "[2023-04-25 05:13:38 PM] training....\n",
      "[2023-04-25 05:13:38 PM] training complete\n",
      "[2023-04-25 05:13:38 PM] training replay buffer....\n",
      "[2023-04-25 05:13:38 PM] training complete\n",
      "[2023-04-25 05:15:17 PM] training....\n",
      "[2023-04-25 05:15:17 PM] training complete\n",
      "[2023-04-25 05:15:17 PM] training replay buffer....\n",
      "[2023-04-25 05:15:17 PM] training complete\n",
      "[2023-04-25 05:16:46 PM] training....\n",
      "[2023-04-25 05:16:47 PM] training complete\n",
      "[2023-04-25 05:16:47 PM] training replay buffer....\n",
      "[2023-04-25 05:16:47 PM] training complete\n",
      "[2023-04-25 05:18:17 PM] training....\n",
      "[2023-04-25 05:18:17 PM] training complete\n",
      "[2023-04-25 05:18:17 PM] training replay buffer....\n",
      "[2023-04-25 05:18:17 PM] training complete\n",
      "[2023-04-25 05:19:46 PM] training....\n",
      "[2023-04-25 05:19:46 PM] training complete\n",
      "[2023-04-25 05:19:46 PM] training replay buffer....\n",
      "[2023-04-25 05:19:46 PM] training complete\n",
      "[2023-04-25 05:21:17 PM] training....\n",
      "[2023-04-25 05:21:17 PM] training complete\n",
      "[2023-04-25 05:21:17 PM] training replay buffer....\n",
      "[2023-04-25 05:21:17 PM] training complete\n",
      "[2023-04-25 05:22:47 PM] training....\n",
      "[2023-04-25 05:22:47 PM] training complete\n",
      "[2023-04-25 05:22:47 PM] training replay buffer....\n",
      "[2023-04-25 05:22:47 PM] training complete\n",
      "[2023-04-25 05:24:17 PM] training....\n",
      "[2023-04-25 05:24:18 PM] training complete\n",
      "[2023-04-25 05:24:18 PM] training replay buffer....\n",
      "[2023-04-25 05:24:18 PM] training complete\n",
      "[2023-04-25 05:25:49 PM] training....\n",
      "[2023-04-25 05:25:49 PM] training complete\n",
      "[2023-04-25 05:25:49 PM] training replay buffer....\n",
      "[2023-04-25 05:25:49 PM] training complete\n",
      "[2023-04-25 05:27:17 PM] training....\n",
      "[2023-04-25 05:27:17 PM] training complete\n",
      "[2023-04-25 05:27:17 PM] training replay buffer....\n",
      "[2023-04-25 05:27:17 PM] training complete\n",
      "[2023-04-25 05:28:44 PM] training....\n",
      "[2023-04-25 05:28:45 PM] training complete\n",
      "[2023-04-25 05:28:45 PM] training replay buffer....\n",
      "[2023-04-25 05:28:45 PM] training complete\n",
      "[2023-04-25 05:30:12 PM] training....\n",
      "[2023-04-25 05:30:13 PM] training complete\n",
      "[2023-04-25 05:30:13 PM] training replay buffer....\n",
      "[2023-04-25 05:30:13 PM] training complete\n",
      "[2023-04-25 05:31:44 PM] training....\n",
      "[2023-04-25 05:31:44 PM] training complete\n",
      "[2023-04-25 05:31:44 PM] training replay buffer....\n",
      "[2023-04-25 05:31:44 PM] training complete\n",
      "[2023-04-25 05:33:14 PM] training....\n",
      "[2023-04-25 05:33:14 PM] training complete\n",
      "[2023-04-25 05:33:14 PM] training replay buffer....\n",
      "[2023-04-25 05:33:14 PM] training complete\n",
      "[2023-04-25 05:34:44 PM] training....\n",
      "[2023-04-25 05:34:45 PM] training complete\n",
      "[2023-04-25 05:34:45 PM] training replay buffer....\n",
      "[2023-04-25 05:34:45 PM] training complete\n",
      "[2023-04-25 05:36:16 PM] training....\n",
      "[2023-04-25 05:36:16 PM] training complete\n",
      "[2023-04-25 05:36:16 PM] training replay buffer....\n",
      "[2023-04-25 05:36:16 PM] training complete\n",
      "[2023-04-25 05:37:45 PM] training....\n",
      "[2023-04-25 05:37:46 PM] training complete\n",
      "[2023-04-25 05:37:46 PM] training replay buffer....\n",
      "[2023-04-25 05:37:46 PM] training complete\n",
      "[2023-04-25 05:39:13 PM] training....\n",
      "[2023-04-25 05:39:14 PM] training complete\n",
      "[2023-04-25 05:39:14 PM] training replay buffer....\n",
      "[2023-04-25 05:39:14 PM] training complete\n",
      "[2023-04-25 05:40:42 PM] training....\n",
      "[2023-04-25 05:40:42 PM] training complete\n",
      "[2023-04-25 05:40:42 PM] training replay buffer....\n",
      "[2023-04-25 05:40:42 PM] training complete\n",
      "[2023-04-25 05:42:10 PM] training....\n",
      "[2023-04-25 05:42:10 PM] training complete\n",
      "[2023-04-25 05:42:10 PM] training replay buffer....\n",
      "[2023-04-25 05:42:10 PM] training complete\n",
      "[2023-04-25 05:43:38 PM] training....\n",
      "[2023-04-25 05:43:38 PM] training complete\n",
      "[2023-04-25 05:43:38 PM] training replay buffer....\n",
      "[2023-04-25 05:43:38 PM] training complete\n",
      "[2023-04-25 05:45:08 PM] training....\n",
      "[2023-04-25 05:45:08 PM] training complete\n",
      "[2023-04-25 05:45:08 PM] training replay buffer....\n",
      "[2023-04-25 05:45:08 PM] training complete\n",
      "[2023-04-25 05:46:38 PM] training....\n",
      "[2023-04-25 05:46:38 PM] training complete\n",
      "[2023-04-25 05:46:38 PM] training replay buffer....\n",
      "[2023-04-25 05:46:38 PM] training complete\n",
      "[2023-04-25 05:48:06 PM] training....\n",
      "[2023-04-25 05:48:06 PM] training complete\n",
      "[2023-04-25 05:48:06 PM] training replay buffer....\n",
      "[2023-04-25 05:48:06 PM] training complete\n",
      "[2023-04-25 05:49:35 PM] training....\n",
      "[2023-04-25 05:49:35 PM] training complete\n",
      "[2023-04-25 05:49:35 PM] training replay buffer....\n",
      "[2023-04-25 05:49:35 PM] training complete\n",
      "[2023-04-25 05:51:03 PM] training....\n",
      "[2023-04-25 05:51:03 PM] training complete\n",
      "[2023-04-25 05:51:03 PM] training replay buffer....\n",
      "[2023-04-25 05:51:03 PM] training complete\n",
      "[2023-04-25 05:52:31 PM] training....\n",
      "[2023-04-25 05:52:32 PM] training complete\n",
      "[2023-04-25 05:52:32 PM] training replay buffer....\n",
      "[2023-04-25 05:52:32 PM] training complete\n",
      "[2023-04-25 05:54:01 PM] training....\n",
      "[2023-04-25 05:54:02 PM] training complete\n",
      "[2023-04-25 05:54:02 PM] training replay buffer....\n",
      "[2023-04-25 05:54:02 PM] training complete\n",
      "[2023-04-25 05:55:30 PM] training....\n",
      "[2023-04-25 05:55:30 PM] training complete\n",
      "[2023-04-25 05:55:30 PM] training replay buffer....\n",
      "[2023-04-25 05:55:30 PM] training complete\n",
      "[2023-04-25 05:56:58 PM] training....\n",
      "[2023-04-25 05:56:58 PM] training complete\n",
      "[2023-04-25 05:56:58 PM] training replay buffer....\n",
      "[2023-04-25 05:56:58 PM] training complete\n",
      "[2023-04-25 05:58:28 PM] training....\n",
      "[2023-04-25 05:58:28 PM] training complete\n",
      "[2023-04-25 05:58:28 PM] training replay buffer....\n",
      "[2023-04-25 05:58:28 PM] training complete\n",
      "[2023-04-25 05:59:54 PM] training....\n",
      "[2023-04-25 05:59:55 PM] training complete\n",
      "[2023-04-25 05:59:55 PM] training replay buffer....\n",
      "[2023-04-25 05:59:55 PM] training complete\n",
      "[2023-04-25 06:01:24 PM] training....\n",
      "[2023-04-25 06:01:24 PM] training complete\n",
      "[2023-04-25 06:01:24 PM] training replay buffer....\n",
      "[2023-04-25 06:01:24 PM] training complete\n",
      "[2023-04-25 06:02:52 PM] training....\n",
      "[2023-04-25 06:02:52 PM] training complete\n",
      "[2023-04-25 06:02:52 PM] training replay buffer....\n",
      "[2023-04-25 06:02:52 PM] training complete\n",
      "[2023-04-25 06:04:20 PM] training....\n",
      "[2023-04-25 06:04:21 PM] training complete\n",
      "[2023-04-25 06:04:21 PM] training replay buffer....\n",
      "[2023-04-25 06:04:21 PM] training complete\n",
      "[2023-04-25 06:05:48 PM] training....\n",
      "[2023-04-25 06:05:48 PM] training complete\n",
      "[2023-04-25 06:05:48 PM] training replay buffer....\n",
      "[2023-04-25 06:05:48 PM] training complete\n",
      "[2023-04-25 06:07:14 PM] training....\n",
      "[2023-04-25 06:07:14 PM] training complete\n",
      "[2023-04-25 06:07:14 PM] training replay buffer....\n",
      "[2023-04-25 06:07:14 PM] training complete\n",
      "[2023-04-25 06:08:40 PM] training....\n",
      "[2023-04-25 06:08:40 PM] training complete\n",
      "[2023-04-25 06:08:40 PM] training replay buffer....\n",
      "[2023-04-25 06:08:40 PM] training complete\n",
      "[2023-04-25 06:10:10 PM] training....\n",
      "[2023-04-25 06:10:10 PM] training complete\n",
      "[2023-04-25 06:10:10 PM] training replay buffer....\n",
      "[2023-04-25 06:10:10 PM] training complete\n",
      "[2023-04-25 06:11:37 PM] training....\n",
      "[2023-04-25 06:11:37 PM] training complete\n",
      "[2023-04-25 06:11:37 PM] training replay buffer....\n",
      "[2023-04-25 06:11:37 PM] training complete\n",
      "[2023-04-25 06:13:05 PM] training....\n",
      "[2023-04-25 06:13:05 PM] training complete\n",
      "[2023-04-25 06:13:05 PM] training replay buffer....\n",
      "[2023-04-25 06:13:05 PM] training complete\n",
      "[2023-04-25 06:14:33 PM] training....\n",
      "[2023-04-25 06:14:33 PM] training complete\n",
      "[2023-04-25 06:14:33 PM] training replay buffer....\n",
      "[2023-04-25 06:14:33 PM] training complete\n",
      "[2023-04-25 06:16:02 PM] training....\n",
      "[2023-04-25 06:16:02 PM] training complete\n",
      "[2023-04-25 06:16:02 PM] training replay buffer....\n",
      "[2023-04-25 06:16:02 PM] training complete\n",
      "[2023-04-25 06:17:30 PM] training....\n",
      "[2023-04-25 06:17:30 PM] training complete\n",
      "[2023-04-25 06:17:30 PM] training replay buffer....\n",
      "[2023-04-25 06:17:30 PM] training complete\n",
      "[2023-04-25 06:18:59 PM] training....\n",
      "[2023-04-25 06:18:59 PM] training complete\n",
      "[2023-04-25 06:18:59 PM] training replay buffer....\n",
      "[2023-04-25 06:18:59 PM] training complete\n",
      "[2023-04-25 06:20:27 PM] training....\n",
      "[2023-04-25 06:20:27 PM] training complete\n",
      "[2023-04-25 06:20:27 PM] training replay buffer....\n",
      "[2023-04-25 06:20:27 PM] training complete\n",
      "[2023-04-25 06:21:53 PM] training....\n",
      "[2023-04-25 06:21:54 PM] training complete\n",
      "[2023-04-25 06:21:54 PM] training replay buffer....\n",
      "[2023-04-25 06:21:54 PM] training complete\n",
      "[2023-04-25 06:23:22 PM] training....\n",
      "[2023-04-25 06:23:22 PM] training complete\n",
      "[2023-04-25 06:23:22 PM] training replay buffer....\n",
      "[2023-04-25 06:23:22 PM] training complete\n",
      "[2023-04-25 06:24:52 PM] training....\n",
      "[2023-04-25 06:24:53 PM] training complete\n",
      "[2023-04-25 06:24:53 PM] training replay buffer....\n",
      "[2023-04-25 06:24:53 PM] training complete\n",
      "[2023-04-25 06:26:23 PM] training....\n",
      "[2023-04-25 06:26:24 PM] training complete\n",
      "[2023-04-25 06:26:24 PM] training replay buffer....\n",
      "[2023-04-25 06:26:24 PM] training complete\n",
      "[2023-04-25 06:27:52 PM] training....\n",
      "[2023-04-25 06:27:52 PM] training complete\n",
      "[2023-04-25 06:27:52 PM] training replay buffer....\n",
      "[2023-04-25 06:27:52 PM] training complete\n",
      "[2023-04-25 06:29:20 PM] training....\n",
      "[2023-04-25 06:29:20 PM] training complete\n",
      "[2023-04-25 06:29:20 PM] training replay buffer....\n",
      "[2023-04-25 06:29:20 PM] training complete\n",
      "[2023-04-25 06:30:50 PM] training....\n",
      "[2023-04-25 06:30:50 PM] training complete\n",
      "[2023-04-25 06:30:50 PM] training replay buffer....\n",
      "[2023-04-25 06:30:50 PM] training complete\n",
      "[2023-04-25 06:32:20 PM] training....\n",
      "[2023-04-25 06:32:20 PM] training complete\n",
      "[2023-04-25 06:32:20 PM] training replay buffer....\n",
      "[2023-04-25 06:32:20 PM] training complete\n",
      "[2023-04-25 06:33:49 PM] training....\n",
      "[2023-04-25 06:33:49 PM] training complete\n",
      "[2023-04-25 06:33:49 PM] training replay buffer....\n",
      "[2023-04-25 06:33:49 PM] training complete\n",
      "[2023-04-25 06:35:19 PM] training....\n",
      "[2023-04-25 06:35:19 PM] training complete\n",
      "[2023-04-25 06:35:19 PM] training replay buffer....\n",
      "[2023-04-25 06:35:19 PM] training complete\n",
      "[2023-04-25 06:36:48 PM] training....\n",
      "[2023-04-25 06:36:48 PM] training complete\n",
      "[2023-04-25 06:36:48 PM] training replay buffer....\n",
      "[2023-04-25 06:36:48 PM] training complete\n",
      "[2023-04-25 06:38:16 PM] training....\n",
      "[2023-04-25 06:38:16 PM] training complete\n",
      "[2023-04-25 06:38:16 PM] training replay buffer....\n",
      "[2023-04-25 06:38:16 PM] training complete\n",
      "[2023-04-25 06:39:46 PM] training....\n",
      "[2023-04-25 06:39:46 PM] training complete\n",
      "[2023-04-25 06:39:46 PM] training replay buffer....\n",
      "[2023-04-25 06:39:46 PM] training complete\n",
      "[2023-04-25 06:41:14 PM] training....\n",
      "[2023-04-25 06:41:15 PM] training complete\n",
      "[2023-04-25 06:41:15 PM] training replay buffer....\n",
      "[2023-04-25 06:41:15 PM] training complete\n",
      "[2023-04-25 06:42:43 PM] training....\n",
      "[2023-04-25 06:42:43 PM] training complete\n",
      "[2023-04-25 06:42:43 PM] training replay buffer....\n",
      "[2023-04-25 06:42:43 PM] training complete\n",
      "[2023-04-25 06:44:13 PM] training....\n",
      "[2023-04-25 06:44:14 PM] training complete\n",
      "[2023-04-25 06:44:14 PM] training replay buffer....\n",
      "[2023-04-25 06:44:14 PM] training complete\n",
      "[2023-04-25 06:45:44 PM] training....\n",
      "[2023-04-25 06:45:44 PM] training complete\n",
      "[2023-04-25 06:45:44 PM] training replay buffer....\n",
      "[2023-04-25 06:45:44 PM] training complete\n",
      "[2023-04-25 06:47:13 PM] training....\n",
      "[2023-04-25 06:47:14 PM] training complete\n",
      "[2023-04-25 06:47:14 PM] training replay buffer....\n",
      "[2023-04-25 06:47:14 PM] training complete\n",
      "[2023-04-25 06:48:42 PM] training....\n",
      "[2023-04-25 06:48:43 PM] training complete\n",
      "[2023-04-25 06:48:43 PM] training replay buffer....\n",
      "[2023-04-25 06:48:43 PM] training complete\n",
      "[2023-04-25 06:50:11 PM] training....\n",
      "[2023-04-25 06:50:11 PM] training complete\n",
      "[2023-04-25 06:50:11 PM] training replay buffer....\n",
      "[2023-04-25 06:50:11 PM] training complete\n",
      "[2023-04-25 06:51:41 PM] training....\n",
      "[2023-04-25 06:51:41 PM] training complete\n",
      "[2023-04-25 06:51:41 PM] training replay buffer....\n",
      "[2023-04-25 06:51:41 PM] training complete\n",
      "[2023-04-25 06:53:12 PM] training....\n",
      "[2023-04-25 06:53:12 PM] training complete\n",
      "[2023-04-25 06:53:12 PM] training replay buffer....\n",
      "[2023-04-25 06:53:12 PM] training complete\n",
      "[2023-04-25 06:54:40 PM] training....\n",
      "[2023-04-25 06:54:40 PM] training complete\n",
      "[2023-04-25 06:54:40 PM] training replay buffer....\n",
      "[2023-04-25 06:54:40 PM] training complete\n",
      "[2023-04-25 06:56:10 PM] training....\n",
      "[2023-04-25 06:56:10 PM] training complete\n",
      "[2023-04-25 06:56:10 PM] training replay buffer....\n",
      "[2023-04-25 06:56:10 PM] training complete\n",
      "[2023-04-25 06:57:40 PM] training....\n",
      "[2023-04-25 06:57:40 PM] training complete\n",
      "[2023-04-25 06:57:40 PM] training replay buffer....\n",
      "[2023-04-25 06:57:40 PM] training complete\n",
      "[2023-04-25 06:59:13 PM] training....\n",
      "[2023-04-25 06:59:13 PM] training complete\n",
      "[2023-04-25 06:59:13 PM] training replay buffer....\n",
      "[2023-04-25 06:59:13 PM] training complete\n",
      "[2023-04-25 07:00:43 PM] training....\n",
      "[2023-04-25 07:00:43 PM] training complete\n",
      "[2023-04-25 07:00:43 PM] training replay buffer....\n",
      "[2023-04-25 07:00:43 PM] training complete\n",
      "[2023-04-25 07:02:12 PM] training....\n",
      "[2023-04-25 07:02:12 PM] training complete\n",
      "[2023-04-25 07:02:12 PM] training replay buffer....\n",
      "[2023-04-25 07:02:12 PM] training complete\n",
      "[2023-04-25 07:03:44 PM] training....\n",
      "[2023-04-25 07:03:45 PM] training complete\n",
      "[2023-04-25 07:03:45 PM] training replay buffer....\n",
      "[2023-04-25 07:03:45 PM] training complete\n",
      "[2023-04-25 07:05:13 PM] training....\n",
      "[2023-04-25 07:05:13 PM] training complete\n",
      "[2023-04-25 07:05:13 PM] training replay buffer....\n",
      "[2023-04-25 07:05:13 PM] training complete\n",
      "[2023-04-25 07:06:44 PM] training....\n",
      "[2023-04-25 07:06:45 PM] training complete\n",
      "[2023-04-25 07:06:45 PM] training replay buffer....\n",
      "[2023-04-25 07:06:45 PM] training complete\n",
      "[2023-04-25 07:08:17 PM] training....\n",
      "[2023-04-25 07:08:17 PM] training complete\n",
      "[2023-04-25 07:08:17 PM] training replay buffer....\n",
      "[2023-04-25 07:08:17 PM] training complete\n",
      "[2023-04-25 07:09:49 PM] training....\n",
      "[2023-04-25 07:09:49 PM] training complete\n",
      "[2023-04-25 07:09:49 PM] training replay buffer....\n",
      "[2023-04-25 07:09:49 PM] training complete\n",
      "[2023-04-25 07:11:22 PM] training....\n",
      "[2023-04-25 07:11:22 PM] training complete\n",
      "[2023-04-25 07:11:22 PM] training replay buffer....\n",
      "[2023-04-25 07:11:22 PM] training complete\n",
      "[2023-04-25 07:12:56 PM] training....\n",
      "[2023-04-25 07:12:56 PM] training complete\n",
      "[2023-04-25 07:12:56 PM] training replay buffer....\n",
      "[2023-04-25 07:12:56 PM] training complete\n",
      "[2023-04-25 07:14:26 PM] training....\n",
      "[2023-04-25 07:14:26 PM] training complete\n",
      "[2023-04-25 07:14:26 PM] training replay buffer....\n",
      "[2023-04-25 07:14:26 PM] training complete\n",
      "[2023-04-25 07:15:59 PM] training....\n",
      "[2023-04-25 07:15:59 PM] training complete\n",
      "[2023-04-25 07:15:59 PM] training replay buffer....\n",
      "[2023-04-25 07:15:59 PM] training complete\n",
      "[2023-04-25 07:17:31 PM] training....\n",
      "[2023-04-25 07:17:31 PM] training complete\n",
      "[2023-04-25 07:17:31 PM] training replay buffer....\n",
      "[2023-04-25 07:17:31 PM] training complete\n",
      "[2023-04-25 07:19:04 PM] training....\n",
      "[2023-04-25 07:19:04 PM] training complete\n",
      "[2023-04-25 07:19:04 PM] training replay buffer....\n",
      "[2023-04-25 07:19:04 PM] training complete\n",
      "[2023-04-25 07:20:34 PM] training....\n",
      "[2023-04-25 07:20:34 PM] training complete\n",
      "[2023-04-25 07:20:34 PM] training replay buffer....\n",
      "[2023-04-25 07:20:34 PM] training complete\n",
      "[2023-04-25 07:22:06 PM] training....\n",
      "[2023-04-25 07:22:06 PM] training complete\n",
      "[2023-04-25 07:22:06 PM] training replay buffer....\n",
      "[2023-04-25 07:22:06 PM] training complete\n",
      "[2023-04-25 07:23:38 PM] training....\n",
      "[2023-04-25 07:23:38 PM] training complete\n",
      "[2023-04-25 07:23:38 PM] training replay buffer....\n",
      "[2023-04-25 07:23:38 PM] training complete\n",
      "[2023-04-25 07:25:07 PM] training....\n",
      "[2023-04-25 07:25:08 PM] training complete\n",
      "[2023-04-25 07:25:08 PM] training replay buffer....\n",
      "[2023-04-25 07:25:08 PM] training complete\n",
      "[2023-04-25 07:26:37 PM] training....\n",
      "[2023-04-25 07:26:37 PM] training complete\n",
      "[2023-04-25 07:26:37 PM] training replay buffer....\n",
      "[2023-04-25 07:26:37 PM] training complete\n",
      "[2023-04-25 07:28:07 PM] training....\n",
      "[2023-04-25 07:28:07 PM] training complete\n",
      "[2023-04-25 07:28:07 PM] training replay buffer....\n",
      "[2023-04-25 07:28:07 PM] training complete\n",
      "[2023-04-25 07:29:41 PM] training....\n",
      "[2023-04-25 07:29:42 PM] training complete\n",
      "[2023-04-25 07:29:42 PM] training replay buffer....\n",
      "[2023-04-25 07:29:42 PM] training complete\n",
      "[2023-04-25 07:31:13 PM] training....\n",
      "[2023-04-25 07:31:13 PM] training complete\n",
      "[2023-04-25 07:31:13 PM] training replay buffer....\n",
      "[2023-04-25 07:31:13 PM] training complete\n",
      "[2023-04-25 07:32:45 PM] training....\n",
      "[2023-04-25 07:32:46 PM] training complete\n",
      "[2023-04-25 07:32:46 PM] training replay buffer....\n",
      "[2023-04-25 07:32:46 PM] training complete\n",
      "[2023-04-25 07:34:17 PM] training....\n",
      "[2023-04-25 07:34:18 PM] training complete\n",
      "[2023-04-25 07:34:18 PM] training replay buffer....\n",
      "[2023-04-25 07:34:18 PM] training complete\n",
      "[2023-04-25 07:35:51 PM] training....\n",
      "[2023-04-25 07:35:51 PM] training complete\n",
      "[2023-04-25 07:35:51 PM] training replay buffer....\n",
      "[2023-04-25 07:35:51 PM] training complete\n",
      "[2023-04-25 07:37:21 PM] training....\n",
      "[2023-04-25 07:37:22 PM] training complete\n",
      "[2023-04-25 07:37:22 PM] training replay buffer....\n",
      "[2023-04-25 07:37:22 PM] training complete\n",
      "[2023-04-25 07:38:51 PM] training....\n",
      "[2023-04-25 07:38:51 PM] training complete\n",
      "[2023-04-25 07:38:51 PM] training replay buffer....\n",
      "[2023-04-25 07:38:51 PM] training complete\n",
      "[2023-04-25 07:40:21 PM] training....\n",
      "[2023-04-25 07:40:21 PM] training complete\n",
      "[2023-04-25 07:40:21 PM] training replay buffer....\n",
      "[2023-04-25 07:40:21 PM] training complete\n",
      "[2023-04-25 07:41:50 PM] training....\n",
      "[2023-04-25 07:41:50 PM] training complete\n",
      "[2023-04-25 07:41:50 PM] training replay buffer....\n",
      "[2023-04-25 07:41:50 PM] training complete\n",
      "[2023-04-25 07:43:20 PM] training....\n",
      "[2023-04-25 07:43:20 PM] training complete\n",
      "[2023-04-25 07:43:20 PM] training replay buffer....\n",
      "[2023-04-25 07:43:20 PM] training complete\n",
      "[2023-04-25 07:44:50 PM] training....\n",
      "[2023-04-25 07:44:50 PM] training complete\n",
      "[2023-04-25 07:44:50 PM] training replay buffer....\n",
      "[2023-04-25 07:44:50 PM] training complete\n",
      "[2023-04-25 07:46:20 PM] training....\n",
      "[2023-04-25 07:46:21 PM] training complete\n",
      "[2023-04-25 07:46:21 PM] training replay buffer....\n",
      "[2023-04-25 07:46:21 PM] training complete\n",
      "[2023-04-25 07:47:51 PM] training....\n",
      "[2023-04-25 07:47:52 PM] training complete\n",
      "[2023-04-25 07:47:52 PM] training replay buffer....\n",
      "[2023-04-25 07:47:52 PM] training complete\n",
      "[2023-04-25 07:49:21 PM] training....\n",
      "[2023-04-25 07:49:21 PM] training complete\n",
      "[2023-04-25 07:49:21 PM] training replay buffer....\n",
      "[2023-04-25 07:49:21 PM] training complete\n",
      "[2023-04-25 07:50:52 PM] training....\n",
      "[2023-04-25 07:50:52 PM] training complete\n",
      "[2023-04-25 07:50:52 PM] training replay buffer....\n",
      "[2023-04-25 07:50:52 PM] training complete\n",
      "[2023-04-25 07:52:25 PM] training....\n",
      "[2023-04-25 07:52:25 PM] training complete\n",
      "[2023-04-25 07:52:25 PM] training replay buffer....\n",
      "[2023-04-25 07:52:25 PM] training complete\n",
      "[2023-04-25 07:53:58 PM] training....\n",
      "[2023-04-25 07:53:58 PM] training complete\n",
      "[2023-04-25 07:53:58 PM] training replay buffer....\n",
      "[2023-04-25 07:53:58 PM] training complete\n",
      "[2023-04-25 07:55:29 PM] training....\n",
      "[2023-04-25 07:55:30 PM] training complete\n",
      "[2023-04-25 07:55:30 PM] training replay buffer....\n",
      "[2023-04-25 07:55:30 PM] training complete\n",
      "[2023-04-25 07:56:59 PM] training....\n",
      "[2023-04-25 07:56:59 PM] training complete\n",
      "[2023-04-25 07:56:59 PM] training replay buffer....\n",
      "[2023-04-25 07:56:59 PM] training complete\n",
      "[2023-04-25 07:58:29 PM] training....\n",
      "[2023-04-25 07:58:29 PM] training complete\n",
      "[2023-04-25 07:58:29 PM] training replay buffer....\n",
      "[2023-04-25 07:58:29 PM] training complete\n",
      "[2023-04-25 08:00:00 PM] training....\n",
      "[2023-04-25 08:00:00 PM] training complete\n",
      "[2023-04-25 08:00:00 PM] training replay buffer....\n",
      "[2023-04-25 08:00:00 PM] training complete\n",
      "[2023-04-25 08:01:29 PM] training....\n",
      "[2023-04-25 08:01:29 PM] training complete\n",
      "[2023-04-25 08:01:29 PM] training replay buffer....\n",
      "[2023-04-25 08:01:29 PM] training complete\n",
      "[2023-04-25 08:02:59 PM] training....\n",
      "[2023-04-25 08:02:59 PM] training complete\n",
      "[2023-04-25 08:02:59 PM] training replay buffer....\n",
      "[2023-04-25 08:02:59 PM] training complete\n",
      "[2023-04-25 08:04:30 PM] training....\n",
      "[2023-04-25 08:04:30 PM] training complete\n",
      "[2023-04-25 08:04:30 PM] training replay buffer....\n",
      "[2023-04-25 08:04:30 PM] training complete\n",
      "[2023-04-25 08:06:02 PM] training....\n",
      "[2023-04-25 08:06:02 PM] training complete\n",
      "[2023-04-25 08:06:02 PM] training replay buffer....\n",
      "[2023-04-25 08:06:02 PM] training complete\n",
      "[2023-04-25 08:07:31 PM] training....\n",
      "[2023-04-25 08:07:31 PM] training complete\n",
      "[2023-04-25 08:07:31 PM] training replay buffer....\n",
      "[2023-04-25 08:07:31 PM] training complete\n",
      "[2023-04-25 08:09:04 PM] training....\n",
      "[2023-04-25 08:09:04 PM] training complete\n",
      "[2023-04-25 08:09:04 PM] training replay buffer....\n",
      "[2023-04-25 08:09:04 PM] training complete\n",
      "[2023-04-25 08:10:37 PM] training....\n",
      "[2023-04-25 08:10:38 PM] training complete\n",
      "[2023-04-25 08:10:38 PM] training replay buffer....\n",
      "[2023-04-25 08:10:38 PM] training complete\n",
      "[2023-04-25 08:12:10 PM] training....\n",
      "[2023-04-25 08:12:10 PM] training complete\n",
      "[2023-04-25 08:12:10 PM] training replay buffer....\n",
      "[2023-04-25 08:12:10 PM] training complete\n",
      "[2023-04-25 08:13:38 PM] training....\n",
      "[2023-04-25 08:13:39 PM] training complete\n",
      "[2023-04-25 08:13:39 PM] training replay buffer....\n",
      "[2023-04-25 08:13:39 PM] training complete\n",
      "[2023-04-25 08:15:08 PM] training....\n",
      "[2023-04-25 08:15:08 PM] training complete\n",
      "[2023-04-25 08:15:08 PM] training replay buffer....\n",
      "[2023-04-25 08:15:08 PM] training complete\n",
      "[2023-04-25 08:16:35 PM] training....\n",
      "[2023-04-25 08:16:35 PM] training complete\n",
      "[2023-04-25 08:16:35 PM] training replay buffer....\n",
      "[2023-04-25 08:16:35 PM] training complete\n",
      "[2023-04-25 08:18:04 PM] training....\n",
      "[2023-04-25 08:18:04 PM] training complete\n",
      "[2023-04-25 08:18:04 PM] training replay buffer....\n",
      "[2023-04-25 08:18:04 PM] training complete\n",
      "[2023-04-25 08:19:34 PM] training....\n",
      "[2023-04-25 08:19:34 PM] training complete\n",
      "[2023-04-25 08:19:34 PM] training replay buffer....\n",
      "[2023-04-25 08:19:34 PM] training complete\n",
      "[2023-04-25 08:21:05 PM] training....\n",
      "[2023-04-25 08:21:06 PM] training complete\n",
      "[2023-04-25 08:21:06 PM] training replay buffer....\n",
      "[2023-04-25 08:21:06 PM] training complete\n",
      "[2023-04-25 08:22:34 PM] training....\n",
      "[2023-04-25 08:22:35 PM] training complete\n",
      "[2023-04-25 08:22:35 PM] training replay buffer....\n",
      "[2023-04-25 08:22:35 PM] training complete\n",
      "[2023-04-25 08:24:05 PM] training....\n",
      "[2023-04-25 08:24:05 PM] training complete\n",
      "[2023-04-25 08:24:05 PM] training replay buffer....\n",
      "[2023-04-25 08:24:05 PM] training complete\n",
      "[2023-04-25 08:25:33 PM] training....\n",
      "[2023-04-25 08:25:33 PM] training complete\n",
      "[2023-04-25 08:25:33 PM] training replay buffer....\n",
      "[2023-04-25 08:25:33 PM] training complete\n",
      "[2023-04-25 08:27:00 PM] training....\n",
      "[2023-04-25 08:27:01 PM] training complete\n",
      "[2023-04-25 08:27:01 PM] training replay buffer....\n",
      "[2023-04-25 08:27:01 PM] training complete\n",
      "[2023-04-25 08:28:30 PM] training....\n",
      "[2023-04-25 08:28:30 PM] training complete\n",
      "[2023-04-25 08:28:30 PM] training replay buffer....\n",
      "[2023-04-25 08:28:30 PM] training complete\n",
      "[2023-04-25 08:30:00 PM] training....\n",
      "[2023-04-25 08:30:01 PM] training complete\n",
      "[2023-04-25 08:30:01 PM] training replay buffer....\n",
      "[2023-04-25 08:30:01 PM] training complete\n",
      "[2023-04-25 08:31:31 PM] training....\n",
      "[2023-04-25 08:31:31 PM] training complete\n",
      "[2023-04-25 08:31:31 PM] training replay buffer....\n",
      "[2023-04-25 08:31:31 PM] training complete\n",
      "[2023-04-25 08:33:02 PM] training....\n",
      "[2023-04-25 08:33:03 PM] training complete\n",
      "[2023-04-25 08:33:03 PM] training replay buffer....\n",
      "[2023-04-25 08:33:03 PM] training complete\n",
      "[2023-04-25 08:34:32 PM] training....\n",
      "[2023-04-25 08:34:32 PM] training complete\n",
      "[2023-04-25 08:34:32 PM] training replay buffer....\n",
      "[2023-04-25 08:34:32 PM] training complete\n",
      "[2023-04-25 08:36:01 PM] training....\n",
      "[2023-04-25 08:36:01 PM] training complete\n",
      "[2023-04-25 08:36:01 PM] training replay buffer....\n",
      "[2023-04-25 08:36:01 PM] training complete\n",
      "[2023-04-25 08:37:30 PM] training....\n",
      "[2023-04-25 08:37:31 PM] training complete\n",
      "[2023-04-25 08:37:31 PM] training replay buffer....\n",
      "[2023-04-25 08:37:31 PM] training complete\n",
      "[2023-04-25 08:39:00 PM] training....\n",
      "[2023-04-25 08:39:00 PM] training complete\n",
      "[2023-04-25 08:39:00 PM] training replay buffer....\n",
      "[2023-04-25 08:39:00 PM] training complete\n",
      "[2023-04-25 08:40:30 PM] training....\n",
      "[2023-04-25 08:40:30 PM] training complete\n",
      "[2023-04-25 08:40:30 PM] training replay buffer....\n",
      "[2023-04-25 08:40:30 PM] training complete\n",
      "[2023-04-25 08:41:59 PM] training....\n",
      "[2023-04-25 08:42:00 PM] training complete\n",
      "[2023-04-25 08:42:00 PM] training replay buffer....\n",
      "[2023-04-25 08:42:00 PM] training complete\n",
      "[2023-04-25 08:43:29 PM] training....\n",
      "[2023-04-25 08:43:29 PM] training complete\n",
      "[2023-04-25 08:43:29 PM] training replay buffer....\n",
      "[2023-04-25 08:43:29 PM] training complete\n",
      "[2023-04-25 08:44:57 PM] training....\n",
      "[2023-04-25 08:44:57 PM] training complete\n",
      "[2023-04-25 08:44:57 PM] training replay buffer....\n",
      "[2023-04-25 08:44:57 PM] training complete\n",
      "[2023-04-25 08:46:29 PM] training....\n",
      "[2023-04-25 08:46:29 PM] training complete\n",
      "[2023-04-25 08:46:29 PM] training replay buffer....\n",
      "[2023-04-25 08:46:29 PM] training complete\n",
      "[2023-04-25 08:48:00 PM] training....\n",
      "[2023-04-25 08:48:00 PM] training complete\n",
      "[2023-04-25 08:48:00 PM] training replay buffer....\n",
      "[2023-04-25 08:48:00 PM] training complete\n",
      "[2023-04-25 08:49:29 PM] training....\n",
      "[2023-04-25 08:49:29 PM] training complete\n",
      "[2023-04-25 08:49:29 PM] training replay buffer....\n",
      "[2023-04-25 08:49:29 PM] training complete\n",
      "[2023-04-25 08:50:59 PM] training....\n",
      "[2023-04-25 08:50:59 PM] training complete\n",
      "[2023-04-25 08:50:59 PM] training replay buffer....\n",
      "[2023-04-25 08:50:59 PM] training complete\n",
      "[2023-04-25 08:52:28 PM] training....\n",
      "[2023-04-25 08:52:28 PM] training complete\n",
      "[2023-04-25 08:52:28 PM] training replay buffer....\n",
      "[2023-04-25 08:52:28 PM] training complete\n",
      "[2023-04-25 08:53:57 PM] training....\n",
      "[2023-04-25 08:53:57 PM] training complete\n",
      "[2023-04-25 08:53:57 PM] training replay buffer....\n",
      "[2023-04-25 08:53:57 PM] training complete\n",
      "[2023-04-25 08:55:29 PM] training....\n",
      "[2023-04-25 08:55:29 PM] training complete\n",
      "[2023-04-25 08:55:29 PM] training replay buffer....\n",
      "[2023-04-25 08:55:29 PM] training complete\n",
      "[2023-04-25 08:57:00 PM] training....\n",
      "[2023-04-25 08:57:00 PM] training complete\n",
      "[2023-04-25 08:57:00 PM] training replay buffer....\n",
      "[2023-04-25 08:57:00 PM] training complete\n",
      "[2023-04-25 08:58:29 PM] training....\n",
      "[2023-04-25 08:58:29 PM] training complete\n",
      "[2023-04-25 08:58:29 PM] training replay buffer....\n",
      "[2023-04-25 08:58:29 PM] training complete\n",
      "[2023-04-25 08:59:58 PM] training....\n",
      "[2023-04-25 08:59:58 PM] training complete\n",
      "[2023-04-25 08:59:58 PM] training replay buffer....\n",
      "[2023-04-25 08:59:58 PM] training complete\n",
      "[2023-04-25 09:01:27 PM] training....\n",
      "[2023-04-25 09:01:27 PM] training complete\n",
      "[2023-04-25 09:01:27 PM] training replay buffer....\n",
      "[2023-04-25 09:01:27 PM] training complete\n",
      "[2023-04-25 09:02:55 PM] training....\n",
      "[2023-04-25 09:02:56 PM] training complete\n",
      "[2023-04-25 09:02:56 PM] training replay buffer....\n",
      "[2023-04-25 09:02:56 PM] training complete\n",
      "[2023-04-25 09:04:25 PM] training....\n",
      "[2023-04-25 09:04:25 PM] training complete\n",
      "[2023-04-25 09:04:25 PM] training replay buffer....\n",
      "[2023-04-25 09:04:25 PM] training complete\n",
      "[2023-04-25 09:05:56 PM] training....\n",
      "[2023-04-25 09:05:56 PM] training complete\n",
      "[2023-04-25 09:05:56 PM] training replay buffer....\n",
      "[2023-04-25 09:05:56 PM] training complete\n",
      "[2023-04-25 09:07:28 PM] training....\n",
      "[2023-04-25 09:07:28 PM] training complete\n",
      "[2023-04-25 09:07:28 PM] training replay buffer....\n",
      "[2023-04-25 09:07:28 PM] training complete\n",
      "[2023-04-25 09:09:02 PM] training....\n",
      "[2023-04-25 09:09:02 PM] training complete\n",
      "[2023-04-25 09:09:02 PM] training replay buffer....\n",
      "[2023-04-25 09:09:02 PM] training complete\n",
      "[2023-04-25 09:10:34 PM] training....\n",
      "[2023-04-25 09:10:34 PM] training complete\n",
      "[2023-04-25 09:10:34 PM] training replay buffer....\n",
      "[2023-04-25 09:10:34 PM] training complete\n",
      "[2023-04-25 09:12:05 PM] training....\n",
      "[2023-04-25 09:12:06 PM] training complete\n",
      "[2023-04-25 09:12:06 PM] training replay buffer....\n",
      "[2023-04-25 09:12:06 PM] training complete\n",
      "[2023-04-25 09:13:38 PM] training....\n",
      "[2023-04-25 09:13:38 PM] training complete\n",
      "[2023-04-25 09:13:38 PM] training replay buffer....\n",
      "[2023-04-25 09:13:38 PM] training complete\n",
      "[2023-04-25 09:15:10 PM] training....\n",
      "[2023-04-25 09:15:10 PM] training complete\n",
      "[2023-04-25 09:15:10 PM] training replay buffer....\n",
      "[2023-04-25 09:15:10 PM] training complete\n",
      "[2023-04-25 09:16:43 PM] training....\n",
      "[2023-04-25 09:16:43 PM] training complete\n",
      "[2023-04-25 09:16:43 PM] training replay buffer....\n",
      "[2023-04-25 09:16:43 PM] training complete\n",
      "[2023-04-25 09:18:13 PM] training....\n",
      "[2023-04-25 09:18:14 PM] training complete\n",
      "[2023-04-25 09:18:14 PM] training replay buffer....\n",
      "[2023-04-25 09:18:14 PM] training complete\n",
      "[2023-04-25 09:19:46 PM] training....\n",
      "[2023-04-25 09:19:47 PM] training complete\n",
      "[2023-04-25 09:19:47 PM] training replay buffer....\n",
      "[2023-04-25 09:19:47 PM] training complete\n",
      "[2023-04-25 09:21:18 PM] training....\n",
      "[2023-04-25 09:21:18 PM] training complete\n",
      "[2023-04-25 09:21:18 PM] training replay buffer....\n",
      "[2023-04-25 09:21:18 PM] training complete\n",
      "[2023-04-25 09:22:49 PM] training....\n",
      "[2023-04-25 09:22:49 PM] training complete\n",
      "[2023-04-25 09:22:49 PM] training replay buffer....\n",
      "[2023-04-25 09:22:49 PM] training complete\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sendOmnetMessage(\"init\") # 입력 끝나면 omnet에 전송\n",
    "    print(\"네트워크 초기화 완료\")\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\"         : 0.0001,\n",
    "        \"gamma\"                 : 0.9,\n",
    "        \"entropy_weight\"        : 0.00001,\n",
    "        \"entropy_gamma\"         : 1.0,\n",
    "        \"lambda\"                : 0.99,\n",
    "        \"eps_clip\"              : 0.1,\n",
    "        \"batch_size\"            : 256,\n",
    "        \"loss_coef\"             : 0.5,\n",
    "        \"job_generate_rate\"     : 0.003,\n",
    "        \"is_train\"              : True,\n",
    "        \"replay_buffer_size\"    : 100,\n",
    "        \"history_learning_time\" : 0,\n",
    "        \"current_learning_time\" : 2,\n",
    "        \"node_feature_num\"      : 4,\n",
    "        \"queue_feature_num\"     : (nodeNum + modelNum) * jobWaitingLength,\n",
    "        \"hidden_feature_num\"    : 64,\n",
    "        \"reward_weight\"         : 1.0/5,\n",
    "        \"node_num\"              : nodeNum,\n",
    "        \"model_num\"             : modelNum,\n",
    "        \"lstm_hidden_num\"       : 64,\n",
    "        \"cpu_load_balance_time\" : 0.1,\n",
    "        \"network_info\"          : networkInfo,\n",
    "        \"path_name\"             : pathName,\n",
    "        \"T_horizon\"             : 50,\n",
    "        \"link_num\"              : 32,\n",
    "        \"state_weight\"          : 1.0,\n",
    "        \"our\"                   : True,\n",
    "        \"imitation_probability\" : 0.0,\n",
    "        \"imitation_gamma\"       : 0.995,\n",
    "    }\n",
    "\n",
    "\n",
    "    main(config)\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            for i in range(10):\n",
    "                print(i)\n",
    "            \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 5)\n",
    "print(a)\n",
    "\n",
    "a = a.unsqueeze(1)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "a = a.repeat(1, 4, 1)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnetTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12c9d4573c12dd45eabff63c44badb6fcd2b70b85de11a1a1b2c23254cbf5db5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
