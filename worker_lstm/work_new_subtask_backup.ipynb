{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mmap\n",
    "import time\n",
    "from time import strftime, localtime\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import import_ipynb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import sys \n",
    "import win32pipe, win32file, pywintypes\n",
    "\n",
    "from actor_no_readout import actor_network\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendOmnetMessage(msg):\n",
    "    win32file.WriteFile(pipe, msg.encode('utf-8'))\n",
    "    \n",
    "def getOmnetMessage():\n",
    "    response_byte = win32file.ReadFile(pipe, BUFFER_SIZE)\n",
    "    response_str = response_byte[1].decode('utf-8')\n",
    "    return response_str\n",
    "\n",
    "def closePipe():\n",
    "    win32file.CloseHandle(pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험 정보 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordExpInfo(config):\n",
    "\n",
    "    networkInfo = config[\"network_info\"]\n",
    "\n",
    "    modelNum = int(networkInfo['modelNum'])\n",
    "    availableJobNum = int(networkInfo['availableJobNum'])\n",
    "    nodeNum = int(networkInfo['nodeNum'])\n",
    "    jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "    adjacency = eval(networkInfo['adjacencyList'])\n",
    "    episode_length = int(networkInfo['episode_length'])\n",
    "    node_capacity = networkInfo['node_capacity']\n",
    "    job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "    node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "    queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "    hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "    reward_weight = 1/modelNum\n",
    "    entropy_weight = config[\"entropy_weight\"]\n",
    "    \n",
    "    info = f\"\"\"\n",
    "    노드 개수 : {nodeNum}\n",
    "    네트워크 최대 job 개수 : {availableJobNum}\n",
    "    job 대기 가능 개수 : {jobWaitingLength}\n",
    "    최대 subtask 개수 : {modelNum}\n",
    "    인접 리스트 : {adjacency}\n",
    "    node_feature_num : {node_feature_num}\n",
    "    queue_feature_num : {queue_feature_num}\n",
    "    episode_length : {episode_length}\n",
    "    node_capacity : {node_capacity}\n",
    "    entropy_weight : {entropy_weight}\n",
    "    reward_weight : {reward_weight}\n",
    "    job_generate_rate : {job_generate_rate}\n",
    "    \"\"\"\n",
    "    print(info)\n",
    "\n",
    "    with open(f'{config[\"path_name\"]}/info.txt', 'w') as f:\n",
    "        f.write(f'{info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "def main(config):\n",
    "    global adjacency, writer\n",
    "\n",
    "    recordExpInfo(config)\n",
    "    \n",
    "    model = actor_network(config)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(total_params)\n",
    "    model.load_state_dict(torch.load(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_reward/history2/model_2500.pth\"))\n",
    "    # model.load_state_dict(torch.load(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_num_test_same_env/history17/model_1100.pth\"))\n",
    "    reward_history = []\n",
    "    v_history = []\n",
    "\n",
    "    adjacency = torch.tensor(adjacency, dtype=torch.long)\n",
    "\n",
    "    step = 1\n",
    "    episode = 1\n",
    "\n",
    "    max_reward = 0\n",
    "\n",
    "    average_reward = 0\n",
    "    average_reward_num = 0\n",
    "\n",
    "    temp_history = deque([])\n",
    "    episode_history = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "\n",
    "    isStop = False\n",
    "    node_selected_num = [0 for i in range(config[\"node_num\"])]\n",
    "    void_selected_num = 0\n",
    "\n",
    "    pre_state_1 = {}\n",
    "    pre_state_2 = {}\n",
    "\n",
    "    void_mask = [0] * config[\"node_num\"] + [1]\n",
    "    unvoid_mask = [1] * config[\"node_num\"] + [0]\n",
    "\n",
    "    episode_total_reward = 0\n",
    "    hidden = (torch.zeros(1, 1, config[\"lstm_hidden_num\"]), torch.zeros(1, 1, config[\"lstm_hidden_num\"]))\n",
    "    \n",
    "    while True:\n",
    "        # time.sleep(config[\"cpu_load_balance_time\"])\n",
    "        \n",
    "        model = model.to('cpu')\n",
    "        model.eval()\n",
    "        msg = getOmnetMessage()\n",
    "        \n",
    "        if msg == \"action\": # omnet의 메세지, state 받으면 됨\n",
    "            sendOmnetMessage(\"ok\")\n",
    "            state_1 = getOmnetMessage()\n",
    "            state_2 = getOmnetMessage()\n",
    "\n",
    "            if len(state_1) == 0:\n",
    "                state_1 = state_2\n",
    "            \n",
    "\n",
    "            if len(pre_state_1) == 0: # action 시작\n",
    "                state_1 = json.loads(state_1) # state 받았으므로 action 하면됨.\n",
    "                state_2 = json.loads(state_2) # state 받았으므로 action 하면됨.\n",
    "                \n",
    "            else:\n",
    "                state_1 = json.loads(state_1)\n",
    "                pre_state_1['jobWaiting'] = state_1['jobWaiting']\n",
    "                pre_state_1['sojournTime'] = state_1['sojournTime']\n",
    "                state_1 = pre_state_1\n",
    "\n",
    "                state_2 = json.loads(state_2)\n",
    "                pre_state_2['jobWaiting'] = state_2['jobWaiting']\n",
    "                pre_state_2['sojournTime'] = state_2['sojournTime']\n",
    "                state_2 = pre_state_2\n",
    "            \n",
    "            sendOmnetMessage(\"ok\") # 답장\n",
    "\n",
    "            \n",
    "            node_waiting_state_1 = torch.tensor(eval(str(state_1['nodeState'])), dtype=torch.float)\n",
    "            node_processing_state_1 = torch.tensor(eval(state_1['nodeProcessing']), dtype=torch.float)\n",
    "            link_state_1 = torch.tensor(eval(state_1['linkWaiting']), dtype=torch.float)\n",
    "            job_waiting_state_1 = torch.tensor(eval(state_1['jobWaiting']), dtype=torch.float)\n",
    "            activated_job_list_1 = eval(state_1['activatedJobList'])\n",
    "            isAction_1 = int(state_1['isAction'])\n",
    "            reward_1 = float(state_1['reward'])\n",
    "            averageLatency_1 = float(state_1['averageLatency'])\n",
    "            completeJobNum_1 = int(state_1['completeJobNum'])\n",
    "            sojournTime_1 = float(state_1['sojournTime'])\n",
    "            #startLatency_1 = float(state_1[\"startLatency\"])\n",
    "\n",
    "            node_waiting_state_2 = torch.tensor(eval(str(state_2['nodeState'])), dtype=torch.float)\n",
    "            node_processing_state_2 = torch.tensor(eval(state_2['nodeProcessing']), dtype=torch.float)\n",
    "            link_state_2 = torch.tensor(eval(state_2['linkWaiting']), dtype=torch.float)\n",
    "            job_waiting_state_2 = torch.tensor(eval(state_2['jobWaiting']), dtype=torch.float)\n",
    "            activated_job_list_2 = eval(state_2['activatedJobList'])\n",
    "            isAction_2 = int(state_2['isAction'])\n",
    "            reward_2 = float(state_2['reward'])\n",
    "            averageLatency_2 = float(state_2['averageLatency'])\n",
    "            completeJobNum_2 = int(state_2['completeJobNum'])\n",
    "            sojournTime_2 = float(state_2['sojournTime'])\n",
    "            #startLatency_2 = float(state_2[\"startLatency\"])\n",
    "\n",
    "            # print(reward_2)\n",
    "\n",
    "\n",
    "\n",
    "            # node_waiting_state_2 = torch.tensor(eval(str(state_1['nodeState'])), dtype=torch.float)\n",
    "            # node_processing_state_2 = torch.tensor(eval(state_1['nodeProcessing']), dtype=torch.float)\n",
    "            # link_state_2 = torch.tensor(eval(state_1['linkWaiting']), dtype=torch.float)\n",
    "            # job_waiting_state_2 = torch.tensor(eval(state_1['jobWaiting']), dtype=torch.float)\n",
    "            # activated_job_list_2 = eval(state_1['activatedJobList'])\n",
    "            # isAction_2 = int(state_1['isAction'])\n",
    "            # reward_2 = float(state_1['reward'])\n",
    "            # averageLatency_2 = float(state_1['averageLatency'])\n",
    "            # completeJobNum_2 = int(state_1['completeJobNum'])\n",
    "            # sojournTime_2 = float(state_1['sojournTime'])\n",
    "\n",
    "            writer.add_scalar(\"completeJobNum/train\", completeJobNum_2 ,step)\n",
    "\n",
    "            #print(node_waiting_state_2)\n",
    "            #print(node_processing_state_2)\n",
    "            \n",
    "\n",
    "            # # 이 timestep에서 발생한 모든 샘플에 똑같은 보상 적용.\n",
    "            # if averageLatency_2 == -1:\n",
    "            #     reward_2 = 0\n",
    "            # else:\n",
    "            #     reward_2 = completeJobNum_2\n",
    "\n",
    "            # reward_2 = startLatency_2 * 100\n",
    "\n",
    "            #print(reward_2)\n",
    "            \n",
    "            writer.add_scalar(\"Reward/train\", reward_2, step)\n",
    "\n",
    "            episode_total_reward += reward_2\n",
    "\n",
    "            if reward_2 != 0:\n",
    "                rewards.append(reward_2)\n",
    "                \n",
    "            first_sample = True\n",
    "            if config[\"is_train\"] and len(pre_state_1) == 0:\n",
    "                if temp_history:\n",
    "                    # temp_history[-1][3] = reward_2\n",
    "                    temp_history[-1][4] = network_state\n",
    "                    temp_history[-1][5] = job_waiting_state\n",
    "\n",
    "                while temp_history:\n",
    "                    history = temp_history.popleft()\n",
    "                    \n",
    "                    # model.history.append(history)\n",
    "                    episode_history.append(history)\n",
    "                    model.put_data(history)\n",
    "\n",
    "            \n",
    "\n",
    "            temp_history = deque([])\n",
    "\n",
    "            job_index = int(state_2['jobIndex'])\n",
    "\n",
    "            #print('sojourn time :', sojournTime)\n",
    "\n",
    "\n",
    "            # node_state_1 = np.concatenate((node_waiting_state_1,node_processing_state_1) ,axis = 1)\n",
    "            #node_state_1 = torch.concat([node_waiting_state_1, node_processing_state_1], dim=1)\n",
    "            node_state_1 = node_waiting_state_1\n",
    "            # node_state_2 = np.concatenate((node_waiting_state_2,node_processing_state_2) ,axis = 1)\n",
    "            #node_state_2 = torch.concat([node_waiting_state_2, node_processing_state_2], dim=1)\n",
    "            node_state_2 = node_waiting_state_2\n",
    "\n",
    "            #print(reward)\n",
    "\n",
    "            # link_state_1 = torch.tensor(link_state_1, dtype=torch.float)\n",
    "            # link_state_2 = torch.tensor(link_state_2, dtype=torch.float)\n",
    "\n",
    "            job_waiting_num = 0\n",
    "            job_waiting_queue = deque()\n",
    "            for job in job_waiting_state_2:\n",
    "                if any(job): # 하나라도 0이 아닌 것 이 있으면 job이 있는것임.\n",
    "                    job_waiting_num += 1\n",
    "                    job_waiting_queue.append(job)\n",
    "            \n",
    "            job_waiting_state_1 = job_waiting_state_1.view(1, -1)\n",
    "            job_waiting_state_2 = job_waiting_state_2.view(1, -1)\n",
    "            # print(job_waiting_state)\n",
    "\n",
    "            network_state_1 = Data(x=node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "            network_state_2 = Data(x=node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "            network_state = [network_state_1, network_state_2]\n",
    "            job_waiting_state = [job_waiting_state_1, job_waiting_state_2]\n",
    "\n",
    "            pre_state_1 = state_1\n",
    "            pre_state_2 = state_2\n",
    "            \n",
    "            if average_reward_num == 0:\n",
    "                average_reward = reward_2\n",
    "                average_reward_num = 1\n",
    "            else:\n",
    "                average_reward = average_reward + (reward_2 - average_reward)/(average_reward_num + 1)\n",
    "                average_reward_num += 1\n",
    "                \n",
    "            if step > 1:\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    node_tag = \"node/\" + str(i) + \"/train\"\n",
    "                    writer.add_scalar(node_tag, node_selected_num[i], step)\n",
    "\n",
    "                writer.add_scalar(\"node/void/train\", void_selected_num, step)\n",
    "                    \n",
    "                node_selected_num = [0 for i in range(config[\"node_num\"])] # node selected num 초기화\n",
    "                void_selected_num = 0\n",
    "\n",
    "                if reward_2 != 0:\n",
    "                    with torch.no_grad():\n",
    "                        state = model.gnn([network_state, job_waiting_state])\n",
    "                        writer.add_scalar(\"Value/train\", torch.mean(model.v(state)), step)\n",
    "                \n",
    "\n",
    "                writer.flush()\n",
    "\n",
    "            \n",
    "            \n",
    "            # print(job_waiting_queue)\n",
    "            if job_waiting_num == 0:\n",
    "                isAction_2 = False\n",
    "                \n",
    "\n",
    "            if isAction_2:\n",
    "                \"\"\"if step % config[\"T_horizon\"] == 0:\n",
    "\n",
    "                    print(\"hello\")\n",
    "\n",
    "                    if config[\"is_train\"]:\n",
    "                        if episode % 100 == 0:\n",
    "                            tm = localtime(time.time())\n",
    "                            time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                            print(f\"[{time_string}] training....\")\n",
    "                        model.train_net()\n",
    "                        if episode % 100 == 0:\n",
    "                            tm = localtime(time.time())\n",
    "                            time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                            print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                        model = model.cpu()\"\"\"\n",
    "\n",
    "\n",
    "                job_idx = job_index\n",
    "                job = job_waiting_queue.popleft()\n",
    "                src = -1\n",
    "                dst = 1\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    if job[i] == -1:\n",
    "                        src = i\n",
    "                    if job[i] == 1:\n",
    "                        dst = i\n",
    "\n",
    "                if src == -1:\n",
    "                    src = dst\n",
    "                    \n",
    "                #print(f\"src : {src}, dst : {dst}\")\n",
    "                #print(job)\n",
    "                subtasks = job[config[\"node_num\"]:]\n",
    "                offloading_vector = []\n",
    "                temp_data = []\n",
    "                scheduling_start = False\n",
    "                # print(subtasks)\n",
    "                step += 1\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    feature = model.gnn([network_state, job_waiting_state])\n",
    "                    feature = F.normalize(feature, dim=1)\n",
    "                    new_feature = feature.unsqueeze(0)\n",
    "                    first_prob, entropy, output, hidden = model.pi([new_feature, hidden])\n",
    "\n",
    "                writer.add_scalar(\"Entropy/train\", torch.mean(entropy).item(), step)\n",
    "                #print(f'prob : {prob}')\n",
    "\n",
    "                # isVoid = F.sigmoid(dists[modelNum].sample())\n",
    "\n",
    "                m = Categorical(first_prob[0][0]) # 첫 번째 batch의 첫 번째 node+void개의 확률들\n",
    "                nodes = m.sample()\n",
    "\n",
    "                node = nodes.item()\n",
    "\n",
    "                #print(f'node : {node}')\n",
    "                \n",
    "                # void action 실험용\n",
    "                # node = nodeNum \n",
    "                \n",
    "                \n",
    "                # void action 뽑으면 void만 업데이트\n",
    "                if node == config[\"node_num\"] and not scheduling_start: \n",
    "                    actions.append(node)\n",
    "                    action_mask = void_mask\n",
    "\n",
    "                    temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, 0, \n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]],\n",
    "                        1, \n",
    "                        0, action_mask, 0]\n",
    "                    )\n",
    "\n",
    "                    sendOmnetMessage(\"void\")\n",
    "\n",
    "                    #print(\"action finish.\")\n",
    "                    \n",
    "                    if getOmnetMessage() == \"ok\":\n",
    "                        void_selected_num += 1\n",
    "\n",
    "                else:\n",
    "                    scheduling_start = True\n",
    "\n",
    "                if scheduling_start:\n",
    "                    \n",
    "                    if random.random() > config[\"imitation_probability\"]:\n",
    "                            config[\"our\"] = True\n",
    "                    else:\n",
    "                        config[\"our\"] = False\n",
    "                    \n",
    "\n",
    "                    for sub_index in range(config[\"model_num\"]):\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            feature = model.gnn([network_state, job_waiting_state])\n",
    "                            feature = F.normalize(feature, dim=1)\n",
    "                            new_feature = feature.unsqueeze(0)\n",
    "                            prob, entropy, output, hidden = model.pi([new_feature, hidden])\n",
    "                            # print(prob)\n",
    "\n",
    "                        writer.add_scalar(\"Entropy/train\", torch.mean(entropy).item(), step)\n",
    "\n",
    "                        output = output[:, :, 0:-1].squeeze(0)\n",
    "\n",
    "                        prob = F.softmax(output, dim=1)\n",
    "                        prob = torch.concat([prob, torch.zeros(1, 1)], dim=1)\n",
    "\n",
    "                        m = Categorical(prob)\n",
    "                        nodes = m.sample()\n",
    "                        action_mask = unvoid_mask\n",
    "\n",
    "\n",
    "                        if config[\"our\"]:\n",
    "                            node = nodes[0].item()\n",
    "                        else:\n",
    "                            node = torch.argmin(node_waiting_state_2[:,0]).item()\n",
    "\n",
    "                        next_node_state_2 = node_state_1.clone() # node_state_1을 node_state2로 복사\n",
    "\n",
    "                        #print(node_state_1)\n",
    "\n",
    "                        next_node_state_1 = node_state_1.clone()\n",
    "                        next_node_state_1[node][3] += subtasks[sub_index]\n",
    "                        next_node_state_1[node][1] = next_node_state_1[node][3] / next_node_state_1[node][2]\n",
    "\n",
    "                        next_network_state_1 = Data(x=next_node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "                        next_network_state_2 = Data(x=next_node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "                        next_network_state = [next_network_state_1, next_network_state_2]\n",
    "                        # allJobWait, allJobWaitTime, power, jobRemain\n",
    "                        next_job_waiting_state = [job_waiting_state_1, job_waiting_state_2]\n",
    "\n",
    "                        temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, 0, \n",
    "                        next_network_state, \n",
    "                        next_job_waiting_state,\n",
    "                        prob[0][node].item(),\n",
    "                        0, action_mask, 0]\n",
    "                        )\n",
    "\n",
    "                        offloading_vector.append(node)\n",
    "                        node_selected_num[node] += 1\n",
    "                        actions.append(node)\n",
    "\n",
    "                        node_state_1 = next_node_state_1.clone()\n",
    "                        node_state_2 = next_node_state_2.clone()\n",
    "\n",
    "                        network_state_1 = Data(x=node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "                        network_state_2 = Data(x=node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "                        network_state = [network_state_1, network_state_2]\n",
    "                        job_waiting_state = next_job_waiting_state\n",
    "\n",
    "                if len(offloading_vector) != 0: # for문을 다 돌면 -> void action 안뽑으면\n",
    "                    # print(offloading_vector)\n",
    "                    msg = str(offloading_vector)\n",
    "                    sendOmnetMessage(msg)\n",
    "                    \n",
    "                    #print(\"action finish.\")\n",
    "                    if(getOmnetMessage() == \"ok\"):\n",
    "                        pass\n",
    "\n",
    "        elif msg == \"stop\":\n",
    "            \n",
    "            sendOmnetMessage(\"ok\")\n",
    "            pre_state_1 = {}\n",
    "            pre_state_2 = {}\n",
    "            \n",
    "        elif msg == \"episode_finish\":\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            # print(len(model.history))\n",
    "\n",
    "            mean = np.mean(rewards)\n",
    "            std = np.std(rewards)\n",
    "\n",
    "            # print(actions)\n",
    "\n",
    "            #print(mean)\n",
    "            #print(std)\n",
    "            #print(rewards)\n",
    "\n",
    "            #for i in range(len(episode_history)):\n",
    "            #    if episode_history[i][3] != 0:\n",
    "            #        episode_history[i][3] = (episode_history[i][3] - mean) / (std + 1e-10)\n",
    "            #        #print((episode_history[i][3] - mean) / (std + 1e-10))\n",
    "\n",
    "            rewards = []\n",
    "            actions = []\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            episodic_reward = getOmnetMessage()\n",
    "            episodic_reward = json.loads(episodic_reward)\n",
    "            \n",
    "            finish_num = float(episodic_reward['reward'])\n",
    "            complete_num = int(episodic_reward['completNum'])\n",
    "            average_latency = float(episodic_reward['averageLatency'])\n",
    "            jitter = episodic_reward['jitter']\n",
    "            jitterMake = episodic_reward['jitterMake']\n",
    "            action_id = episodic_reward['action_id']\n",
    "            action_reward = episodic_reward['action_reward']\n",
    "            #print(list(map(float, jitter.strip().split(\" \"))))\n",
    "            #print(list(map(float, jitterMake.strip().split(\" \"))))\n",
    "            #print(list(map(int, action_id.strip().split(\" \"))))\n",
    "            #print(list(map(float, action_reward.strip().split(\" \"))))\n",
    "\n",
    "\n",
    "            normalized_finish_num = model.return_normalize_reward(finish_num)\n",
    "            \n",
    "            writer.add_scalar(\"EpisodicReward/train\", finish_num, episode)\n",
    "            writer.add_scalar(\"NormalizedEpisodicReward/train\", normalized_finish_num, episode)\n",
    "            writer.add_scalar(\"CompleteNum/train\", complete_num, episode)\n",
    "            writer.add_scalar(\"averageLatency/train\", average_latency ,episode)\n",
    "\n",
    "            # model.history.append(episode_history)\n",
    "            #aaaa = [episode_history[i][2] for i in range(len(episode_history))]\n",
    "            #print(len(aaaa))\n",
    "            #print(aaaa)\n",
    "            #rrrr = [episode_history[i][3] for i in range(len(episode_history))]\n",
    "            #print(len(rrrr))\n",
    "            #print(rrrr)\n",
    "            \n",
    "            model.data = episode_history[:]\n",
    "            data_length = len(model.data)\n",
    "            reward_list = [(data_length - i) * -0.01 for i in range(data_length)]\n",
    "\n",
    "            action_id_list = list(map(int, action_id.strip().split(\" \"))) if action_id != '' else []\n",
    "            action_reward_list = list(map(float, action_reward.strip().split(\" \"))) if action_reward != '' else []\n",
    "\n",
    "            action_id_reward_list = sorted(zip(action_id_list, action_reward_list))\n",
    "\n",
    "            #print(action_id_reward_list)\n",
    "\n",
    "            for i in range(len(action_id_reward_list)):\n",
    "                index = action_id_reward_list[i][0]\n",
    "                if index < data_length:\n",
    "                    reward_list[index] = action_id_reward_list[i][1]\n",
    "\n",
    "            #print(reward_list)\n",
    "\n",
    "            for i in range(len(model.data)):\n",
    "                model.data[i][3] = reward_list[i]\n",
    "\n",
    "            tt = []\n",
    "            for i in range(len(model.data)):\n",
    "                tt.append(model.data[i][3])\n",
    "            #print(tt)\n",
    "            #print(len(model.data))\n",
    "            #print(tt)\n",
    "            episode_history = []\n",
    "            temp_history = deque([])\n",
    "\n",
    "            \n",
    "\n",
    "            episode_total_reward += complete_num\n",
    "\n",
    "            writer.add_scalar(\"episode_total_reward/train\", episode_total_reward, episode)\n",
    "\n",
    "            episode_total_reward = 0\n",
    "            hidden = (torch.zeros(1, 1, config[\"lstm_hidden_num\"]), torch.zeros(1, 1, config[\"lstm_hidden_num\"]))\n",
    "\n",
    "            episode += 1\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            config[\"entropy_weight\"] = max(0.0001, config[\"entropy_weight\"] * config[\"entropy_gamma\"])\n",
    "            config[\"imitation_probability\"] = max(config[\"imitation_gamma\"] * config[\"imitation_probability\"], 0.2)\n",
    "\n",
    "            if finish_num > max_reward:\n",
    "                modelPathName = config[\"path_name\"] + \"/max_model.pth\"\n",
    "                torch.save(model.state_dict(), modelPathName)\n",
    "                max_reward = finish_num\n",
    "\n",
    "            writer.add_scalar(\"AverageReward/train\", average_reward, step)\n",
    "            average_reward = 0\n",
    "            average_reward_num = 0\n",
    "\n",
    "            if config[\"is_train\"]:\n",
    "                \n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training....\")\n",
    "                model.train_net()\n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training replay buffer....\")\n",
    "                model.train_net_history()\n",
    "                if episode % 100 == 0:\n",
    "                    tm = localtime(time.time())\n",
    "                    time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                    print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                model.clear_data()\n",
    "\n",
    "                if episode % 100 == 0:\n",
    "                    modelPathName = config[\"path_name\"] + \"/model.pth\"\n",
    "                    torch.save(model.state_dict(), modelPathName)\n",
    "                    modelPathName = config[\"path_name\"] + f\"/model_{episode}.pth\"\n",
    "                    torch.save(model.state_dict(), modelPathName)\n",
    "\n",
    "                    time.sleep(10)\n",
    "\n",
    "                model.eval()\n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPE_NAME = \"\\\\\\\\.\\\\pipe\\\\worker_right_latency_sub_trace4\"\n",
    "BUFFER_SIZE = 200000\n",
    "\n",
    "try:\n",
    "    pipe = win32pipe.CreateNamedPipe(\n",
    "        PIPE_NAME,\n",
    "        win32pipe.PIPE_ACCESS_DUPLEX,\n",
    "        win32pipe.PIPE_TYPE_MESSAGE | win32pipe.PIPE_READMODE_MESSAGE | win32pipe.PIPE_WAIT,\n",
    "        1,\n",
    "        BUFFER_SIZE,\n",
    "        BUFFER_SIZE,\n",
    "        0,\n",
    "        None\n",
    "    )    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "win32pipe.ConnectNamedPipe(pipe, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = getOmnetMessage()\n",
    "networkInfo = json.loads(initial_message)\n",
    "\n",
    "modelNum = int(networkInfo['modelNum'])\n",
    "availableJobNum = int(networkInfo['availableJobNum'])\n",
    "nodeNum = int(networkInfo['nodeNum'])\n",
    "jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "adjacency = eval(networkInfo['adjacencyList'])\n",
    "episode_length = int(networkInfo['episode_length'])\n",
    "node_capacity = networkInfo['node_capacity']\n",
    "job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "reward_weight = 1/modelNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history8\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_reward\")\n",
    "folderList = glob.glob(\"history*\")\n",
    "\n",
    "pathName = \"history\" + str(len(folderList))\n",
    "\n",
    "print(pathName)\n",
    "\n",
    "os.mkdir(pathName)\n",
    "\n",
    "writer = SummaryWriter(pathName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 초기화 완료\n",
      "\n",
      "    노드 개수 : 5\n",
      "    네트워크 최대 job 개수 : 5\n",
      "    job 대기 가능 개수 : 15\n",
      "    최대 subtask 개수 : 3\n",
      "    인접 리스트 : [[0, 1, 0, 2, 1, 2, 1, 3, 2, 3, 2, 4, 3, 4], [1, 0, 2, 0, 2, 1, 3, 1, 3, 2, 4, 2, 4, 3]]\n",
      "    node_feature_num : 30\n",
      "    queue_feature_num : 120\n",
      "    episode_length : 1000\n",
      "    node_capacity : 0.100000, 0.300000\n",
      "    entropy_weight : 0.0001\n",
      "    reward_weight : 0.3333333333333333\n",
      "    job_generate_rate : 5\n",
      "    \n",
      "1429847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\numpy\\core\\_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\numpy\\core\\_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "c:\\Users\\user\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\numpy\\core\\_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "(109, 'ReadFile', '파이프가 끝났습니다.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\suhwan\\connection_test\\python_agent\\worker_lstm\\work_new_subtask4.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m네트워크 초기화 완료\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m         : \u001b[39m0.00005\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m\"\u001b[39m                 : \u001b[39m0.9\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimitation_gamma\u001b[39m\u001b[39m\"\u001b[39m       : \u001b[39m1.0\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m main(config)\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\suhwan\\connection_test\\python_agent\\worker_lstm\\work_new_subtask4.ipynb Cell 11\u001b[0m in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m msg \u001b[39m=\u001b[39m getOmnetMessage()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mif\u001b[39;00m msg \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m# omnet의 메세지, state 받으면 됨\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     sendOmnetMessage(\u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\suhwan\\connection_test\\python_agent\\worker_lstm\\work_new_subtask4.ipynb Cell 11\u001b[0m in \u001b[0;36mgetOmnetMessage\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetOmnetMessage\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     response_byte \u001b[39m=\u001b[39m win32file\u001b[39m.\u001b[39;49mReadFile(pipe, BUFFER_SIZE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     response_str \u001b[39m=\u001b[39m response_byte[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/suhwan/connection_test/python_agent/worker_lstm/work_new_subtask4.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response_str\n",
      "\u001b[1;31merror\u001b[0m: (109, 'ReadFile', '파이프가 끝났습니다.')"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sendOmnetMessage(\"init\") # 입력 끝나면 omnet에 전송\n",
    "    print(\"네트워크 초기화 완료\")\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\"         : 0.00005,\n",
    "        \"gamma\"                 : 0.9,\n",
    "        \"entropy_weight\"        : 0.0001,\n",
    "        \"entropy_gamma\"         : 0.9998,\n",
    "        \"lambda\"                : 0.99,\n",
    "        \"eps_clip\"              : 0.08,\n",
    "        \"batch_size\"            : 256,\n",
    "        \"loss_coef\"             : 0.5,\n",
    "        \"job_generate_rate\"     : 0.003,\n",
    "        \"is_train\"              : False,\n",
    "        \"replay_buffer_size\"    : 100,\n",
    "        \"history_learning_time\" : 0,\n",
    "        \"current_learning_time\" : 2,\n",
    "        \"node_feature_num\"      : 4,\n",
    "        \"queue_feature_num\"     : (nodeNum + modelNum) * jobWaitingLength,\n",
    "        \"hidden_feature_num\"    : 128,\n",
    "        \"reward_weight\"         : 1.0/1,\n",
    "        \"node_num\"              : nodeNum,\n",
    "        \"model_num\"             : modelNum,\n",
    "        \"lstm_hidden_num\"       : 128,\n",
    "        \"cpu_load_balance_time\" : 0.1,\n",
    "        \"network_info\"          : networkInfo,\n",
    "        \"path_name\"             : pathName,\n",
    "        \"T_horizon\"             : 1000,\n",
    "        \"link_num\"              : 32,\n",
    "        \"state_weight\"          : 1.0,\n",
    "        \"our\"                   : True,\n",
    "        \"imitation_probability\" : 0.0,\n",
    "        \"imitation_gamma\"       : 1.0,\n",
    "    }\n",
    "\n",
    "\n",
    "    main(config)\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "[(0, 0.027814), (1, 0.033636), (2, 0.087693), (3, 0.036799), (4, 0.033607), (5, 0.030417), (6, 0.029843), (7, 0.013596), (8, 0.0479), (9, 0.074262), (10, 0.040415), (11, 0.043085), (12, 0.040076), (13, 0.025153), (14, 0.03274), (15, 0.022581), (16, 0.028499), (17, 0.106345), (18, 0.131984), (19, 0.033249), (20, 0.085203), (21, 0.098693), (22, 0.036045), (23, 0.078513), (24, 0.241986), (25, 0.008629), (26, 0.079723), (27, 0.093197), (28, 0.009598), (29, 0.03463), (30, 0.034807), (31, 0.010012), (33, 0.023464), (34, 0.041557), (35, 0.11446), (36, 0.027988), (39, 0.053074), (40, 0.026495), (41, 0.027873), (42, 0.098693), (43, 0.028241), (45, 0.062686), (46, 0.030221)]\n"
     ]
    }
   ],
   "source": [
    "a = [0, 3, 9, 1, 6, 12, 4, 10, 2, 5, 13, 18, 11, 21, 14, 7, 19, 24, 22, 20, 8, 23, 15, 27, 16, 17, 33, 34, 35, 25, 30, 28, 36, 39, 26, 29, 31, 40, 42, 41, 43, 45, 46]\n",
    "b = [0.027814, 0.036799, 0.074262, 0.033636, 0.029843, 0.040076, 0.033607, 0.040415, 0.087693, 0.030417, 0.025153, 0.131984, 0.043085, 0.098693, 0.03274, 0.013596, 0.033249, 0.241986, 0.036045, 0.085203, 0.0479, 0.078513, 0.022581, 0.093197, 0.028499, 0.106345, 0.023464, 0.041557, 0.11446, 0.008629, 0.034807, 0.009598, 0.027988, 0.053074, 0.079723, 0.03463, 0.010012, 0.026495, 0.098693, 0.027873, 0.028241, 0.062686, 0.030221]\n",
    "\n",
    "\n",
    "d = sorted(zip(a,b))\n",
    "print(len(d))\n",
    "print(sorted(d))\n",
    "\n",
    "# model.data 개수에 맞춰야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            for i in range(10):\n",
    "                print(i)\n",
    "            \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 5)\n",
    "print(a)\n",
    "\n",
    "a = a.unsqueeze(1)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "a = a.repeat(1, 4, 1)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnetTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12c9d4573c12dd45eabff63c44badb6fcd2b70b85de11a1a1b2c23254cbf5db5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
