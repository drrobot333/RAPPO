{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import time\n",
    "from time import strftime, localtime\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "import import_ipynb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import sys \n",
    "import win32pipe, win32file, pywintypes\n",
    "\n",
    "from actor import actor_network\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendOmnetMessage(msg):\n",
    "    win32file.WriteFile(pipe, msg.encode('utf-8'))\n",
    "    \n",
    "def getOmnetMessage():\n",
    "    response_byte = win32file.ReadFile(pipe, BUFFER_SIZE)\n",
    "    response_str = response_byte[1].decode('utf-8')\n",
    "    return response_str\n",
    "\n",
    "def closePipe():\n",
    "    win32file.CloseHandle(pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험 정보 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordExpInfo(config):\n",
    "\n",
    "    networkInfo = config[\"network_info\"]\n",
    "\n",
    "    modelNum = int(networkInfo['modelNum'])\n",
    "    availableJobNum = int(networkInfo['availableJobNum'])\n",
    "    nodeNum = int(networkInfo['nodeNum'])\n",
    "    jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "    adjacency = eval(networkInfo['adjacencyList'])\n",
    "    episode_length = int(networkInfo['episode_length'])\n",
    "    node_capacity = networkInfo['node_capacity']\n",
    "    job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "    node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "    queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "    hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "    reward_weight = 1/modelNum\n",
    "    entropy_weight = config[\"entropy_weight\"]\n",
    "    \n",
    "    info = f\"\"\"\n",
    "    노드 개수 : {nodeNum}\n",
    "    네트워크 최대 job 개수 : {availableJobNum}\n",
    "    job 대기 가능 개수 : {jobWaitingLength}\n",
    "    최대 subtask 개수 : {modelNum}\n",
    "    인접 리스트 : {adjacency}\n",
    "    node_feature_num : {node_feature_num}\n",
    "    queue_feature_num : {queue_feature_num}\n",
    "    episode_length : {episode_length}\n",
    "    node_capacity : {node_capacity}\n",
    "    entropy_weight : {entropy_weight}\n",
    "    reward_weight : {reward_weight}\n",
    "    job_generate_rate : {job_generate_rate}\n",
    "    \"\"\"\n",
    "    print(info)\n",
    "\n",
    "    with open(f'{config[\"path_name\"]}/info.txt', 'w') as f:\n",
    "        f.write(f'{info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    global adjacency, writer\n",
    "\n",
    "    recordExpInfo(config)\n",
    "    \n",
    "    model = actor_network(config)\n",
    "    # model.load_state_dict(torch.load(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_num_test_same_env/history8/model.pth\"))\n",
    "    reward_history = []\n",
    "    v_history = []\n",
    "\n",
    "    adjacency = torch.tensor(adjacency, dtype=torch.long)\n",
    "\n",
    "    step = 1\n",
    "    episode = 1\n",
    "\n",
    "    max_reward = 0\n",
    "\n",
    "    average_reward = 0\n",
    "    average_reward_num = 0\n",
    "\n",
    "    temp_history = deque([])\n",
    "\n",
    "    isStop = False\n",
    "    node_selected_num = [0 for i in range(config[\"node_num\"])]\n",
    "    void_selected_num = 0\n",
    "\n",
    "    pre_state_1 = {}\n",
    "    pre_state_2 = {}\n",
    "\n",
    "    void_mask = [0] * config[\"node_num\"] + [1]\n",
    "    unvoid_mask = [1] * config[\"node_num\"] + [0]\n",
    "\n",
    "    episode_total_reward = 0\n",
    "    hidden = (torch.zeros(1, 1, config[\"lstm_hidden_num\"]), torch.zeros(1, 1, config[\"lstm_hidden_num\"]))\n",
    "    \n",
    "    while True:\n",
    "        # time.sleep(config[\"cpu_load_balance_time\"])\n",
    "        \n",
    "        model = model.to('cpu')\n",
    "        msg = getOmnetMessage()\n",
    "        \n",
    "        if msg == \"action\": # omnet의 메세지, state 받으면 됨\n",
    "            sendOmnetMessage(\"ok\")\n",
    "            state_1 = getOmnetMessage()\n",
    "            state_2 = getOmnetMessage()\n",
    "\n",
    "            if len(state_1) == 0:\n",
    "                state_1 = state_2\n",
    "            \n",
    "\n",
    "            if len(pre_state_1) == 0: # action 시작\n",
    "                state_1 = json.loads(state_1) # state 받았으므로 action 하면됨.\n",
    "                state_2 = json.loads(state_2) # state 받았으므로 action 하면됨.\n",
    "                \n",
    "            else:\n",
    "                state_1 = json.loads(state_1)\n",
    "                pre_state_1['jobWaiting'] = state_1['jobWaiting']\n",
    "                pre_state_1['sojournTime'] = state_1['sojournTime']\n",
    "                state_1 = pre_state_1\n",
    "\n",
    "                state_2 = json.loads(state_2)\n",
    "                pre_state_2['jobWaiting'] = state_2['jobWaiting']\n",
    "                pre_state_2['sojournTime'] = state_2['sojournTime']\n",
    "                state_2 = pre_state_2\n",
    "            \n",
    "            sendOmnetMessage(\"ok\") # 답장\n",
    "\n",
    "            \n",
    "            node_waiting_state_1 = torch.tensor(eval(str(state_1['nodeState'])), dtype=torch.float)\n",
    "            node_processing_state_1 = torch.tensor(eval(state_1['nodeProcessing']), dtype=torch.float)\n",
    "            link_state_1 = torch.tensor(eval(state_1['linkWaiting']), dtype=torch.float)\n",
    "            job_waiting_state_1 = torch.tensor(eval(state_1['jobWaiting']), dtype=torch.float)\n",
    "            activated_job_list_1 = eval(state_1['activatedJobList'])\n",
    "            isAction_1 = int(state_1['isAction'])\n",
    "            reward_1 = float(state_1['reward'])\n",
    "            averageLatency_1 = float(state_1['averageLatency'])\n",
    "            completeJobNum_1 = int(state_1['completeJobNum'])\n",
    "            sojournTime_1 = float(state_1['sojournTime'])\n",
    "\n",
    "            node_waiting_state_2 = torch.tensor(eval(str(state_2['nodeState'])), dtype=torch.float)\n",
    "            node_processing_state_2 = torch.tensor(eval(state_2['nodeProcessing']), dtype=torch.float)\n",
    "            link_state_2 = torch.tensor(eval(state_2['linkWaiting']), dtype=torch.float)\n",
    "            job_waiting_state_2 = torch.tensor(eval(state_2['jobWaiting']), dtype=torch.float)\n",
    "            activated_job_list_2 = eval(state_2['activatedJobList'])\n",
    "            isAction_2 = int(state_2['isAction'])\n",
    "            reward_2 = float(state_2['reward'])\n",
    "            averageLatency_2 = float(state_2['averageLatency'])\n",
    "            completeJobNum_2 = int(state_2['completeJobNum'])\n",
    "            sojournTime_2 = float(state_2['sojournTime'])\n",
    "\n",
    "            writer.add_scalar(\"completeJobNum/train\", completeJobNum_2 ,step)\n",
    "\n",
    "            #print(node_waiting_state_2)\n",
    "            #print(node_processing_state_2)\n",
    "            \n",
    "\n",
    "            # # 이 timestep에서 발생한 모든 샘플에 똑같은 보상 적용.\n",
    "            # if averageLatency_2 == -1:\n",
    "            #     reward_2 = 0\n",
    "            # else:\n",
    "            #     reward_2 = completeJobNum_2\n",
    "            \n",
    "            writer.add_scalar(\"Reward/train\", reward_2, step)\n",
    "\n",
    "            episode_total_reward += reward_2\n",
    "                \n",
    "            first_sample = True\n",
    "            if config[\"is_train\"] and len(pre_state_1) == 0:\n",
    "                while temp_history:\n",
    "                    history = temp_history.popleft()\n",
    "                    history[3] = reward_2\n",
    "                    history[4] = network_state\n",
    "                    history[5] = job_waiting_state\n",
    "                    model.history.append(history)\n",
    "                    model.put_data(history)\n",
    "\n",
    "            \n",
    "\n",
    "            temp_history = deque([])\n",
    "\n",
    "            job_index = int(state_2['jobIndex'])\n",
    "\n",
    "            #print('sojourn time :', sojournTime)\n",
    "\n",
    "\n",
    "            # node_state_1 = np.concatenate((node_waiting_state_1,node_processing_state_1) ,axis = 1)\n",
    "            #node_state_1 = torch.concat([node_waiting_state_1, node_processing_state_1], dim=1)\n",
    "            node_state_1 = node_waiting_state_1\n",
    "            # node_state_2 = np.concatenate((node_waiting_state_2,node_processing_state_2) ,axis = 1)\n",
    "            #node_state_2 = torch.concat([node_waiting_state_2, node_processing_state_2], dim=1)\n",
    "            node_state_2 = node_waiting_state_2\n",
    "\n",
    "            #print(reward)\n",
    "\n",
    "            # link_state_1 = torch.tensor(link_state_1, dtype=torch.float)\n",
    "            # link_state_2 = torch.tensor(link_state_2, dtype=torch.float)\n",
    "\n",
    "            job_waiting_num = 0\n",
    "            job_waiting_queue = deque()\n",
    "            for job in job_waiting_state_2:\n",
    "                if any(job): # 하나라도 0이 아닌 것 이 있으면 job이 있는것임.\n",
    "                    job_waiting_num += 1\n",
    "                    job_waiting_queue.append(job)\n",
    "            \n",
    "            job_waiting_state_1 = job_waiting_state_1.view(1, -1)\n",
    "            job_waiting_state_2 = job_waiting_state_2.view(1, -1)\n",
    "            # print(job_waiting_state)\n",
    "\n",
    "            network_state_1 = Data(x=node_state_1, edge_attr=link_state_1, edge_index=adjacency)\n",
    "            network_state_2 = Data(x=node_state_2, edge_attr=link_state_2, edge_index=adjacency)\n",
    "\n",
    "            network_state = [network_state_1, network_state_2]\n",
    "            job_waiting_state = [job_waiting_state_1, job_waiting_state_2]\n",
    "\n",
    "            pre_state_1 = state_1\n",
    "            pre_state_2 = state_2\n",
    "            \n",
    "            if average_reward_num == 0:\n",
    "                average_reward = reward_2\n",
    "                average_reward_num = 1\n",
    "            else:\n",
    "                average_reward = average_reward + (reward_2 - average_reward)/(average_reward_num + 1)\n",
    "                average_reward_num += 1\n",
    "                \n",
    "            if step > 1:\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    node_tag = \"node/\" + str(i) + \"/train\"\n",
    "                    writer.add_scalar(node_tag, node_selected_num[i], step)\n",
    "\n",
    "                writer.add_scalar(\"node/void/train\", void_selected_num, step)\n",
    "                    \n",
    "                node_selected_num = [0 for i in range(config[\"node_num\"])] # node selected num 초기화\n",
    "                void_selected_num = 0\n",
    "\n",
    "                if reward_2 != 0:\n",
    "                    with torch.no_grad():\n",
    "                        state = model.gnn([network_state, job_waiting_state])\n",
    "                        writer.add_scalar(\"Value/train\", torch.mean(model.v(state)), step)\n",
    "                \n",
    "\n",
    "                writer.flush()\n",
    "\n",
    "            \n",
    "            \n",
    "            # print(job_waiting_queue)\n",
    "            if job_waiting_num == 0:\n",
    "                isAction_2 = False\n",
    "                \n",
    "\n",
    "            if isAction_2:\n",
    "                if step % config[\"T_horizon\"] == 0:\n",
    "                    if config[\"is_train\"]:\n",
    "                        tm = localtime(time.time())\n",
    "                        time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                        print(f\"[{time_string}] training....\")\n",
    "                        model.train_net()\n",
    "                        tm = localtime(time.time())\n",
    "                        time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                        print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                        model = model.cpu()\n",
    "\n",
    "\n",
    "                job_idx = job_index\n",
    "                job = job_waiting_queue.popleft()\n",
    "                src = -1\n",
    "                dst = 1\n",
    "                for i in range(config[\"node_num\"]):\n",
    "                    if job[i] == -1:\n",
    "                        src = i\n",
    "                    if job[i] == 1:\n",
    "                        dst = i\n",
    "\n",
    "                if src == -1:\n",
    "                    src = dst\n",
    "                    \n",
    "                #print(f\"src : {src}, dst : {dst}\")\n",
    "                #print(job)\n",
    "                subtasks = job[config[\"node_num\"]:]\n",
    "                offloading_vector = []\n",
    "                temp_data = []\n",
    "                scheduling_start = False\n",
    "                # print(subtasks)\n",
    "                step += 1\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    feature = model.gnn([network_state, job_waiting_state])\n",
    "                    new_feature = feature.repeat(config[\"model_num\"], 1).unsqueeze(0)\n",
    "                    first_prob, entropy, output, hidden = model.pi([new_feature, hidden])\n",
    "\n",
    "                writer.add_scalar(\"Entropy/train\", torch.mean(entropy).item(), step)\n",
    "                #print(f'prob : {prob}')\n",
    "\n",
    "                # isVoid = F.sigmoid(dists[modelNum].sample())\n",
    "\n",
    "                m = Categorical(first_prob[0][0]) # 첫 번째 batch의 첫 번째 node+void개의 확률들\n",
    "                nodes = m.sample()\n",
    "\n",
    "                node = nodes.item()\n",
    "\n",
    "                #print(f'node : {node}')\n",
    "                \n",
    "                # void action 실험용\n",
    "                # node = nodeNum \n",
    "                \n",
    "                \n",
    "                # void action 뽑으면 void만 업데이트\n",
    "                if node == config[\"node_num\"] and not scheduling_start: \n",
    "                    action_mask = void_mask\n",
    "\n",
    "                    temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, 0, \n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]],\n",
    "                        1, \n",
    "                        0, action_mask, 0]\n",
    "                    )\n",
    "\n",
    "                    sendOmnetMessage(\"void\")\n",
    "\n",
    "                    #print(\"action finish.\")\n",
    "                    \n",
    "                    if getOmnetMessage() == \"ok\":\n",
    "                        void_selected_num += 1\n",
    "\n",
    "                else:\n",
    "                    scheduling_start = True\n",
    "\n",
    "                if scheduling_start:\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        feature = model.gnn([network_state, job_waiting_state])\n",
    "                        # print(feature)\n",
    "                        new_feature = feature.repeat(config[\"model_num\"], 1).unsqueeze(0)\n",
    "                        prob, entropy, output, hidden = model.pi([new_feature, hidden])\n",
    "\n",
    "                    output = output[:, :, 0:-1].squeeze(0)\n",
    "\n",
    "\n",
    "                    prob = F.softmax(output, dim=1)\n",
    "                    prob = torch.concat([prob, torch.zeros(config[\"model_num\"], 1)], dim=1)\n",
    "\n",
    "\n",
    "                    m = Categorical(prob)\n",
    "                    nodes = m.sample()\n",
    "                    action_mask = unvoid_mask\n",
    "\n",
    "                    for index in range(config[\"model_num\"]):\n",
    "\n",
    "                        node = nodes[index].item()\n",
    "\n",
    "                        temp_history.append([\n",
    "                        [network_state[0], network_state[1]], \n",
    "                        [job_waiting_state[0], job_waiting_state[1]], \n",
    "                        node, -1, \n",
    "                        [-1, -1], \n",
    "                        [-1, -1],\n",
    "                        prob[index][node].item(),\n",
    "                        0, action_mask, index]\n",
    "                        )\n",
    "\n",
    "                        offloading_vector.append(node)\n",
    "                        node_selected_num[node] += 1\n",
    "                    \n",
    "                if len(offloading_vector) != 0: # for문을 다 돌면 -> void action 안뽑으면\n",
    "                    # print(offloading_vector)\n",
    "                    msg = str(offloading_vector)\n",
    "                    sendOmnetMessage(msg)\n",
    "                    \n",
    "                    #print(\"action finish.\")\n",
    "                    if(getOmnetMessage() == \"ok\"):\n",
    "                        pass\n",
    "\n",
    "        elif msg == \"stop\":\n",
    "            \n",
    "            sendOmnetMessage(\"ok\")\n",
    "            pre_state_1 = {}\n",
    "            pre_state_2 = {}\n",
    "            \n",
    "        elif msg == \"episode_finish\":\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            # print(len(model.history))\n",
    "\n",
    "            episodic_reward = getOmnetMessage()\n",
    "            episodic_reward = json.loads(episodic_reward)\n",
    "            \n",
    "            finish_num = float(episodic_reward['reward'])\n",
    "            complete_num = int(episodic_reward['completNum'])\n",
    "            average_latency = float(episodic_reward['averageLatency'])\n",
    "\n",
    "            normalized_finish_num = model.return_normalize_reward(finish_num)\n",
    "            \n",
    "            writer.add_scalar(\"EpisodicReward/train\", finish_num, episode)\n",
    "            writer.add_scalar(\"NormalizedEpisodicReward/train\", normalized_finish_num, episode)\n",
    "            writer.add_scalar(\"CompleteNum/train\", complete_num, episode)\n",
    "            writer.add_scalar(\"averageLatency/train\", average_latency ,episode)\n",
    "\n",
    "            \n",
    "\n",
    "            episode_total_reward += complete_num\n",
    "\n",
    "            writer.add_scalar(\"episode_total_reward/train\", episode_total_reward, episode)\n",
    "\n",
    "            episode_total_reward = 0\n",
    "            hidden = (torch.zeros(1, 1, config[\"lstm_hidden_num\"]), torch.zeros(1, 1, config[\"lstm_hidden_num\"]))\n",
    "\n",
    "            episode += 1\n",
    "            sendOmnetMessage(\"ok\")\n",
    "\n",
    "            if finish_num > max_reward:\n",
    "                modelPathName = config[\"path_name\"] + \"/max_model.pth\"\n",
    "                torch.save(model.state_dict(), modelPathName)\n",
    "                max_reward = finish_num\n",
    "\n",
    "            writer.add_scalar(\"AverageReward/train\", average_reward, step)\n",
    "            average_reward = 0\n",
    "            average_reward_num = 0\n",
    "\n",
    "            if config[\"is_train\"]:\n",
    "            \n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training....\")\n",
    "                model.train_net()\n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training replay buffer....\")\n",
    "                model.train_net_history()\n",
    "                tm = localtime(time.time())\n",
    "                time_string = strftime('%Y-%m-%d %I:%M:%S %p', tm)\n",
    "                print(f\"[{time_string}] training complete\")\n",
    "\n",
    "                model.clear_data()\n",
    "\n",
    "                if episode % 100 == 0:\n",
    "                    modelPathName = config[\"path_name\"] + f\"/model_{episode}.pth\"\n",
    "                    torch.save(model.state_dict(), modelPathName)\n",
    "\n",
    "                    time.sleep(10)\n",
    "                \n",
    "                modelPathName = config[\"path_name\"] + \"/model.pth\"\n",
    "                torch.save(model.state_dict(), modelPathName)\n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통신 관련 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPE_NAME = \"\\\\\\\\.\\\\pipe\\\\worker_new2\"\n",
    "BUFFER_SIZE = 200000\n",
    "\n",
    "try:\n",
    "    pipe = win32pipe.CreateNamedPipe(\n",
    "        PIPE_NAME,\n",
    "        win32pipe.PIPE_ACCESS_DUPLEX,\n",
    "        win32pipe.PIPE_TYPE_MESSAGE | win32pipe.PIPE_READMODE_MESSAGE | win32pipe.PIPE_WAIT,\n",
    "        1,\n",
    "        BUFFER_SIZE,\n",
    "        BUFFER_SIZE,\n",
    "        0,\n",
    "        None\n",
    "    )    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "win32pipe.ConnectNamedPipe(pipe, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = getOmnetMessage()\n",
    "networkInfo = json.loads(initial_message)\n",
    "\n",
    "modelNum = int(networkInfo['modelNum'])\n",
    "availableJobNum = int(networkInfo['availableJobNum'])\n",
    "nodeNum = int(networkInfo['nodeNum'])\n",
    "jobWaitingLength = int(networkInfo['jobWaitingQueueLength'])\n",
    "adjacency = eval(networkInfo['adjacencyList'])\n",
    "episode_length = int(networkInfo['episode_length'])\n",
    "node_capacity = networkInfo['node_capacity']\n",
    "job_generate_rate = networkInfo['job_generate_rate']\n",
    "\n",
    "node_feature_num = 2 * (modelNum * availableJobNum)\n",
    "queue_feature_num = (nodeNum + modelNum) * jobWaitingLength\n",
    "hidden_feature_num = 10*(node_feature_num + queue_feature_num)\n",
    "reward_weight = 1/modelNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/user/Desktop/suhwan/connection_test/python_agent/experiment/subtask_num_test_same_env\")\n",
    "folderList = glob.glob(\"history*\")\n",
    "\n",
    "pathName = \"history\" + str(len(folderList))\n",
    "\n",
    "print(pathName)\n",
    "\n",
    "os.mkdir(pathName)\n",
    "\n",
    "writer = SummaryWriter(pathName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    sendOmnetMessage(\"init\") # 입력 끝나면 omnet에 전송\n",
    "    print(\"네트워크 초기화 완료\")\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\"         : 0.0001,\n",
    "        \"gamma\"                 : 0.99,\n",
    "        \"entropy_weight\"        : 0.06,\n",
    "        \"lambda\"                : 0.99,\n",
    "        \"eps_clip\"              : 0.1,\n",
    "        \"batch_size\"            : 256,\n",
    "        \"loss_coef\"             : 0.5,\n",
    "        \"job_generate_rate\"     : 0.003,\n",
    "        \"is_train\"              : True,\n",
    "        \"replay_buffer_size\"    : 1000,\n",
    "        \"history_learning_time\" : 0,\n",
    "        \"current_learning_time\" : 2,\n",
    "        \"node_feature_num\"      : 4,\n",
    "        \"queue_feature_num\"     : (nodeNum + modelNum) * jobWaitingLength,\n",
    "        \"hidden_feature_num\"    : 30,\n",
    "        \"reward_weight\"         : 1.0/1,\n",
    "        \"node_num\"              : nodeNum,\n",
    "        \"model_num\"             : modelNum,\n",
    "        \"lstm_hidden_num\"       : 30,\n",
    "        \"cpu_load_balance_time\" : 0.1,\n",
    "        \"network_info\"          : networkInfo,\n",
    "        \"path_name\"             : pathName,\n",
    "        \"T_horizon\"             : 60,\n",
    "    }\n",
    "\n",
    "\n",
    "    main(config)\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            for i in range(10):\n",
    "                print(i)\n",
    "            \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 5)\n",
    "print(a)\n",
    "\n",
    "a = a.unsqueeze(1)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "a = a.repeat(1, 4, 1)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnetTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12c9d4573c12dd45eabff63c44badb6fcd2b70b85de11a1a1b2c23254cbf5db5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
